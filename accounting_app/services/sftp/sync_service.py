"""
SFTP åŒæ­¥æœåŠ¡åè°ƒå™¨
è´Ÿè´£æ‰«ææ–‡ä»¶ã€ç®¡ç†ä¸Šä¼ ä»»åŠ¡ã€é‡è¯•é€»è¾‘å’Œå®¡è®¡æ—¥å¿—
"""
import os
import hashlib
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from sqlalchemy.orm import Session
from .sftp_client import SFTPClient
from ...models import SFTPUploadJob
from ...utils.audit_logger import log_event

logger = logging.getLogger(__name__)


class SFTPSyncService:
    """SFTPåŒæ­¥æœåŠ¡ï¼šæ–‡ä»¶æ‰«æã€ä¸Šä¼ ç®¡ç†ã€é‡è¯•ç­–ç•¥"""
    
    # å…è®¸ä¸Šä¼ çš„æ–‡ä»¶æ‰©å±•å
    ALLOWED_EXTENSIONS = {'.csv', '.xlsx', '.xls'}
    
    # æ–‡ä»¶å¤¹åˆ°payload_typeçš„æ˜ å°„
    FOLDER_MAPPING = {
        "sales": "sales",
        "suppliers": "suppliers",
        "payments": "payments",
        "customers": "customers",
        "bank": "bank",
        "payroll": "payroll",
        "loan": "loan"
    }
    
    def __init__(self, db_session: Session, company_id: int = 1):
        """
        åˆå§‹åŒ–åŒæ­¥æœåŠ¡
        
        Args:
            db_session: æ•°æ®åº“ä¼šè¯
            company_id: å…¬å¸IDï¼ˆé»˜è®¤1ï¼‰
        """
        self.db = db_session
        self.company_id = company_id
        self.sftp_client = SFTPClient()
        self.base_upload_dir = "accounting_data/uploads"
    
    def scan_and_upload_files(self, is_manual: bool = False, uploaded_by: str = "system") -> Dict[str, Any]:
        """
        æ‰«ææ‰€æœ‰å¾…ä¸Šä¼ æ–‡ä»¶å¹¶æ‰§è¡Œä¸Šä¼ ï¼ˆæ”¯æŒå¤šå…¬å¸å±‚çº§ç»“æ„ï¼‰
        
        ç›®å½•ç»“æ„ï¼š
        accounting_data/uploads/
            â”œâ”€â”€ company_1/
            â”‚   â”œâ”€â”€ sales/
            â”‚   â”œâ”€â”€ suppliers/
            â”‚   â””â”€â”€ payments/
            â”œâ”€â”€ company_2/
            â”‚   â”œâ”€â”€ sales/
            â”‚   â””â”€â”€ bank/
        
        Args:
            is_manual: æ˜¯å¦æ‰‹åŠ¨è§¦å‘
            uploaded_by: è§¦å‘ç”¨æˆ·
        
        Returns:
            ä¸Šä¼ ç»“æœç»Ÿè®¡
        """
        logger.info(f"ğŸ“‚ Scanning upload directories: {self.base_upload_dir}")
        
        uploaded_count = 0
        failed_count = 0
        skipped_count = 0
        results = []
        
        # ç¡®ä¿åŸºç¡€ç›®å½•å­˜åœ¨
        if not os.path.exists(self.base_upload_dir):
            logger.warning(f"âš ï¸  Base upload directory not found: {self.base_upload_dir}")
            return {
                "success": True,
                "uploaded": 0,
                "failed": 0,
                "skipped": 0,
                "total_scanned": 0,
                "results": []
            }
        
        # ğŸ”„ å‘åå…¼å®¹ï¼šæ£€æµ‹ç›®å½•ç»“æ„ï¼ˆlegacyå¹³é¢ç»“æ„ vs æ–°çš„å¤šå…¬å¸å±‚çº§ï¼‰
        is_legacy_layout = any(
            folder_name in os.listdir(self.base_upload_dir)
            for folder_name in self.FOLDER_MAPPING.keys()
        )
        
        if is_legacy_layout:
            # Legacy å¹³é¢ç»“æ„ï¼šaccounting_data/uploads/sales/
            logger.info("ğŸ“ Detected legacy flat directory structure")
            company_folders = ["."]  # å½“å‰ç›®å½•ä½œä¸ºå•ä¸€å…¬å¸
        else:
            # æ–°çš„å¤šå…¬å¸å±‚çº§ç»“æ„ï¼šaccounting_data/uploads/company_1/sales/
            logger.info("ğŸ“ Detected multi-company directory structure")
            company_folders = [
                f for f in os.listdir(self.base_upload_dir)
                if os.path.isdir(os.path.join(self.base_upload_dir, f))
                and not f.startswith('.')  # æ’é™¤éšè—æ–‡ä»¶å¤¹
            ]
        
        # éå†æ‰€æœ‰å…¬å¸ç›®å½•
        for company_folder in company_folders:
            if company_folder == ".":
                company_path = self.base_upload_dir
                company_name = "default"
                logger.info(f"ğŸ“ Scanning legacy flat structure")
            else:
                company_path = os.path.join(self.base_upload_dir, company_folder)
                company_name = company_folder
                
                # ğŸ”’ å®‰å…¨æ€§ï¼šéªŒè¯company_folderåªåŒ…å«å®‰å…¨å­—ç¬¦
                if not self._is_safe_folder_name(company_folder):
                    logger.error(f"âŒ Unsafe company folder name detected: {company_folder}")
                    continue
                
                # ğŸ”’ å®‰å…¨æ€§ï¼šç¡®ä¿è¿™æ˜¯çœŸå®ç›®å½•ï¼Œéç¬¦å·é“¾æ¥
                if os.path.islink(company_path):
                    logger.error(f"âŒ Symlink detected, skipping: {company_folder}")
                    continue
                
                logger.info(f"ğŸ“ Scanning company folder: {company_folder}")
            
            # éå†æ¯ä¸ªæ•°æ®ç±»å‹æ–‡ä»¶å¤¹
            for folder_name, payload_type in self.FOLDER_MAPPING.items():
                folder_path = os.path.join(company_path, folder_name)
                
                # ç¡®ä¿æ–‡ä»¶å¤¹å­˜åœ¨
                if not os.path.exists(folder_path):
                    continue
                
                # è·å–æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶ï¼ˆæ”¯æŒ CSV, XLSX, XLSï¼‰
                try:
                    files = [
                        f for f in os.listdir(folder_path)
                        if os.path.isfile(os.path.join(folder_path, f))
                        and os.path.splitext(f)[1].lower() in self.ALLOWED_EXTENSIONS
                        and not f.startswith('.')  # æ’é™¤éšè—æ–‡ä»¶
                    ]
                except PermissionError as e:
                    logger.error(f"âŒ Permission denied: {folder_path} | {e}")
                    continue
                
                if files:
                    logger.info(f"ğŸ“„ Found {len(files)} files in {company_folder}/{folder_name}/")
                
                # ä¸Šä¼ æ¯ä¸ªæ–‡ä»¶
                for file_name in files:
                    local_path = os.path.join(folder_path, file_name)
                    
                    # å®‰å…¨æ€§æ£€æŸ¥ï¼šç¡®ä¿è·¯å¾„è§„èŒƒåŒ–ï¼ˆé˜²æ­¢ç›®å½•éå†æ”»å‡»ï¼‰
                    normalized_path = os.path.normpath(os.path.abspath(local_path))
                    base_abs = os.path.normpath(os.path.abspath(self.base_upload_dir))
                    if not normalized_path.startswith(base_abs):
                        logger.error(f"âŒ Path traversal attempt detected: {local_path}")
                        continue
                    
                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²æˆåŠŸä¸Šä¼ è¿‡ï¼ˆåŸºäºå†…å®¹å“ˆå¸Œï¼‰
                    if self._is_file_already_uploaded(local_path):
                        logger.debug(f"â­ï¸  File already uploaded successfully, skipping: {file_name}")
                        skipped_count += 1
                        continue
                    
                    # æ‰§è¡Œä¸Šä¼ 
                    result = self._upload_single_file(
                        local_path=local_path,
                        file_name=file_name,
                        payload_type=payload_type,
                        is_manual=is_manual,
                        uploaded_by=uploaded_by,
                        company_folder=company_name
                    )
                    
                    results.append(result)
                    
                    if result['success']:
                        uploaded_count += 1
                    else:
                        failed_count += 1
        
        summary = {
            "success": True,
            "uploaded": uploaded_count,
            "failed": failed_count,
            "skipped": skipped_count,
            "total_scanned": uploaded_count + failed_count + skipped_count,
            "results": results
        }
        
        logger.info(f"âœ… Sync completed: {uploaded_count} uploaded, {failed_count} failed, {skipped_count} skipped")
        
        # è®°å½•å®¡è®¡æ—¥å¿—
        log_event(
            db=self.db,
            action_type="SFTP_SYNC",
            entity_type="sftp_upload_job",
            description=f"SFTP sync completed: {uploaded_count} uploaded, {failed_count} failed",
            metadata=summary
        )
        
        return summary
    
    def _upload_single_file(self, local_path: str, file_name: str, payload_type: str,
                           is_manual: bool, uploaded_by: str, company_folder: str = "unknown") -> Dict[str, Any]:
        """
        ä¸Šä¼ å•ä¸ªæ–‡ä»¶å¹¶è®°å½•åˆ°æ•°æ®åº“
        
        Args:
            local_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
            file_name: æ–‡ä»¶å
            payload_type: æ•°æ®ç±»å‹
            is_manual: æ˜¯å¦æ‰‹åŠ¨è§¦å‘
            uploaded_by: è§¦å‘ç”¨æˆ·
        
        Returns:
            ä¸Šä¼ ç»“æœ
        """
        try:
            # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
            file_hash = self._calculate_file_hash(local_path)
            file_size = os.path.getsize(local_path)
            
            # è·å–è¿œç¨‹è·¯å¾„ï¼ˆåŒ…å«å…¬å¸æ–‡ä»¶å¤¹å±‚çº§ï¼‰
            remote_base = self.sftp_client.get_payload_remote_path(payload_type)
            remote_dir = os.path.join(remote_base, company_folder).replace('\\', '/')
            remote_path = os.path.join(remote_dir, file_name).replace('\\', '/')
            
            # ç”Ÿæˆjobç¼–å·
            job_number = self._generate_job_number()
            
            # åˆ›å»ºä¸Šä¼ ä»»åŠ¡è®°å½•
            job = SFTPUploadJob(
                company_id=self.company_id,
                job_number=job_number,
                file_path=local_path,
                file_name=file_name,
                payload_type=payload_type,
                remote_path=remote_path,
                file_size=file_size,
                file_hash=file_hash,
                status='uploading',
                attempts=1,
                sftp_host=self.sftp_client.host,
                sftp_username=self.sftp_client.username,
                uploaded_by=uploaded_by,
                is_manual=is_manual,
                started_at=datetime.utcnow()
            )
            
            self.db.add(job)
            self.db.commit()
            
            logger.info(f"ğŸ“¤ Uploading {file_name} â†’ {remote_path}")
            
            # æ‰§è¡Œä¸Šä¼ 
            upload_result = self.sftp_client.upload_file(local_path, remote_path)
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            if upload_result['success']:
                job.status = 'success'
                job.completed_at = datetime.utcnow()
                job.duration_seconds = upload_result.get('duration', 0)
                logger.info(f"âœ… Upload successful: {file_name} ({job.job_number})")
            else:
                job.status = 'failed'
                job.last_error = upload_result.get('error', 'Unknown error')
                logger.error(f"âŒ Upload failed: {file_name} | Error: {job.last_error}")
            
            self.db.commit()
            
            # è®°å½•å®¡è®¡æ—¥å¿—
            log_event(
                db=self.db,
                action_type="SFTP_UPLOAD",
                entity_type="sftp_upload_job",
                entity_id=job.id,
                description=f"File upload {'succeeded' if upload_result['success'] else 'failed'}: {file_name}",
                metadata={
                    "file_name": file_name,
                    "payload_type": payload_type,
                    "file_size": file_size,
                    "remote_path": remote_path,
                    "success": upload_result['success']
                }
            )
            
            return {
                "success": upload_result['success'],
                "job_number": job_number,
                "file_name": file_name,
                "payload_type": payload_type,
                "file_size": file_size,
                "message": upload_result.get('message', '')
            }
            
        except Exception as e:
            logger.error(f"âŒ Exception uploading {file_name}: {e}")
            return {
                "success": False,
                "file_name": file_name,
                "payload_type": payload_type,
                "error": str(e)
            }
    
    def retry_failed_uploads(self) -> Dict[str, Any]:
        """
        é‡è¯•æ‰€æœ‰å¤±è´¥çš„ä¸Šä¼ ä»»åŠ¡
        
        Returns:
            é‡è¯•ç»“æœç»Ÿè®¡
        """
        # æŸ¥æ‰¾éœ€è¦é‡è¯•çš„ä»»åŠ¡
        now = datetime.utcnow()
        failed_jobs = self.db.query(SFTPUploadJob).filter(
            SFTPUploadJob.company_id == self.company_id,
            SFTPUploadJob.status.in_(['failed', 'retry']),
            SFTPUploadJob.attempts < SFTPUploadJob.max_attempts,
            (SFTPUploadJob.next_retry_at == None) | (SFTPUploadJob.next_retry_at <= now)
        ).all()
        
        logger.info(f"ğŸ”„ Found {len(failed_jobs)} failed jobs to retry")
        
        retried_count = 0
        succeeded_count = 0
        failed_count = 0
        
        for job in failed_jobs:
            # å¢åŠ å°è¯•æ¬¡æ•°
            job.attempts += 1
            job.status = 'uploading'
            job.started_at = datetime.utcnow()
            self.db.commit()
            
            # é‡æ–°ä¸Šä¼ 
            upload_result = self.sftp_client.upload_file(job.file_path, job.remote_path)
            
            if upload_result['success']:
                job.status = 'success'
                job.completed_at = datetime.utcnow()
                job.duration_seconds = upload_result.get('duration', 0)
                job.last_error = None
                succeeded_count += 1
                logger.info(f"âœ… Retry successful: {job.file_name} (attempt {job.attempts})")
            else:
                job.status = 'failed' if job.attempts >= job.max_attempts else 'retry'
                job.last_error = upload_result.get('error', 'Unknown error')
                # æŒ‡æ•°é€€é¿ï¼š2åˆ†é’Ÿã€4åˆ†é’Ÿã€8åˆ†é’Ÿ
                backoff_minutes = 2 ** job.attempts
                job.next_retry_at = datetime.utcnow() + timedelta(minutes=backoff_minutes)
                failed_count += 1
                logger.warning(f"âš ï¸  Retry failed: {job.file_name} (attempt {job.attempts}/{job.max_attempts})")
            
            self.db.commit()
            retried_count += 1
        
        summary = {
            "success": True,
            "retried": retried_count,
            "succeeded": succeeded_count,
            "failed": failed_count
        }
        
        logger.info(f"ğŸ”„ Retry completed: {succeeded_count} succeeded, {failed_count} failed")
        
        return summary
    
    def _is_file_already_uploaded(self, local_path: str) -> bool:
        """
        æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²æˆåŠŸä¸Šä¼ 
        
        Args:
            local_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
        
        Returns:
            æ˜¯å¦å·²ä¸Šä¼ 
        """
        file_hash = self._calculate_file_hash(local_path)
        
        existing_job = self.db.query(SFTPUploadJob).filter(
            SFTPUploadJob.company_id == self.company_id,
            SFTPUploadJob.file_hash == file_hash,
            SFTPUploadJob.status == 'success'
        ).first()
        
        return existing_job is not None
    
    def _calculate_file_hash(self, file_path: str) -> str:
        """
        è®¡ç®—æ–‡ä»¶SHA256å“ˆå¸Œ
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
        
        Returns:
            SHA256å“ˆå¸Œå€¼ï¼ˆhexæ ¼å¼ï¼‰
        """
        sha256 = hashlib.sha256()
        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(4096), b''):
                sha256.update(chunk)
        return sha256.hexdigest()
    
    def _generate_job_number(self) -> str:
        """
        ç”Ÿæˆå”¯ä¸€çš„jobç¼–å·
        
        Returns:
            Jobç¼–å·æ ¼å¼: SFTP-YYYYMMDD-HHMMSS-XXX
        """
        timestamp = datetime.utcnow().strftime('%Y%m%d-%H%M%S')
        
        # è·å–ä»Šå¤©å·²æœ‰çš„jobæ•°é‡
        today_start = datetime.utcnow().replace(hour=0, minute=0, second=0, microsecond=0)
        count = self.db.query(SFTPUploadJob).filter(
            SFTPUploadJob.created_at >= today_start
        ).count()
        
        sequence = str(count + 1).zfill(3)
        
        return f"SFTP-{timestamp}-{sequence}"
    
    def _is_safe_folder_name(self, folder_name: str) -> bool:
        """
        éªŒè¯æ–‡ä»¶å¤¹åç§°åªåŒ…å«å®‰å…¨å­—ç¬¦
        
        Args:
            folder_name: æ–‡ä»¶å¤¹åç§°
        
        Returns:
            æ˜¯å¦å®‰å…¨
        """
        import re
        # åªå…è®¸å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿ã€è¿å­—ç¬¦
        pattern = r'^[a-zA-Z0-9_-]+$'
        return bool(re.match(pattern, folder_name))
    
    def get_upload_statistics(self) -> Dict[str, Any]:
        """
        è·å–ä¸Šä¼ ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡æ•°æ®
        """
        total = self.db.query(SFTPUploadJob).filter(
            SFTPUploadJob.company_id == self.company_id
        ).count()
        
        success = self.db.query(SFTPUploadJob).filter(
            SFTPUploadJob.company_id == self.company_id,
            SFTPUploadJob.status == 'success'
        ).count()
        
        failed = self.db.query(SFTPUploadJob).filter(
            SFTPUploadJob.company_id == self.company_id,
            SFTPUploadJob.status == 'failed'
        ).count()
        
        pending = self.db.query(SFTPUploadJob).filter(
            SFTPUploadJob.company_id == self.company_id,
            SFTPUploadJob.status.in_(['pending', 'retry', 'uploading'])
        ).count()
        
        return {
            "total_jobs": total,
            "successful": success,
            "failed": failed,
            "pending": pending,
            "success_rate": round(success / total * 100, 2) if total > 0 else 0
        }

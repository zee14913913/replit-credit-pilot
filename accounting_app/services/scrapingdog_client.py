import os
import requests
import logging
from typing import Optional, Dict, Any
from bs4 import BeautifulSoup

logger = logging.getLogger(__name__)

class ScrapingDogClient:
    """ScrapingDog APIå®¢æˆ·ç«¯ - ç”¨äºçˆ¬å–é©¬æ¥è¥¿äºšé“¶è¡Œè´·æ¬¾æ•°æ®"""
    
    def __init__(self):
        self.api_key = os.getenv('SCRAPINGDOG_API_KEY')
        if not self.api_key:
            raise ValueError("SCRAPINGDOG_API_KEY not found in environment")
        
        self.base_url = "https://api.scrapingdog.com/scrape"
        logger.info("âœ… ScrapingDogå®¢æˆ·ç«¯å·²åˆå§‹åŒ–")
    
    def scrape_url(self, url: str, dynamic: bool = False, premium: bool = False) -> Optional[str]:
        """
        ä½¿ç”¨ScrapingDogçˆ¬å–URL
        
        Args:
            url: ç›®æ ‡URL
            dynamic: æ˜¯å¦ä½¿ç”¨JavaScriptæ¸²æŸ“ï¼ˆ25x creditsï¼‰
            premium: æ˜¯å¦ä½¿ç”¨é«˜çº§ä»£ç†
        
        Returns:
            HTMLå†…å®¹æˆ–None
        """
        params = {
            'api_key': self.api_key,
            'url': url,
            'dynamic': 'true' if dynamic else 'false',
            'premium': 'true' if premium else 'false'
        }
        
        try:
            logger.info(f"ğŸ•·ï¸ çˆ¬å–URL: {url}")
            response = requests.get(self.base_url, params=params, timeout=120)
            
            if response.status_code == 200:
                logger.info(f"âœ… æˆåŠŸçˆ¬å–: {url}")
                return response.text
            else:
                logger.error(f"âŒ çˆ¬å–å¤±è´¥ {url}: HTTP {response.status_code}")
                logger.error(f"å“åº”: {response.text[:200]}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ çˆ¬å–å¼‚å¸¸ {url}: {str(e)}")
            return None
    
    def extract_loan_products(self, html: str, bank_name: str) -> Dict[str, Any]:
        """
        ä»HTMLä¸­æå–è´·æ¬¾äº§å“æ•°æ®
        
        Args:
            html: ç½‘é¡µHTMLå†…å®¹
            bank_name: é“¶è¡Œåç§°
        
        Returns:
            æå–çš„äº§å“æ•°æ®å­—å…¸
        """
        soup = BeautifulSoup(html, 'html.parser')
        
        products = {
            'bank': bank_name,
            'products': [],
            'raw_html_length': len(html)
        }
        
        loan_keywords = [
            'personal loan', 'home loan', 'housing loan', 'mortgage',
            'business loan', 'SME', 'car loan', 'auto loan',
            'debt consolidation', 'refinance', 'financing'
        ]
        
        text_content = soup.get_text().lower()
        
        for keyword in loan_keywords:
            if keyword in text_content:
                products['products'].append({
                    'type': keyword,
                    'found': True
                })
        
        return products

scrapingdog_client = ScrapingDogClient()

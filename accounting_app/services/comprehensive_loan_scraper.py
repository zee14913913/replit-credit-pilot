"""
é©¬æ¥è¥¿äºš68å®¶é‡‘èæœºæ„å®Œæ•´è´·æ¬¾æ•°æ®é‡‡é›†ç³»ç»Ÿ
æ”¯æŒ7ç§è´·æ¬¾äº§å“ç±»å‹çš„è‡ªåŠ¨åŒ–çˆ¬å–
"""
import os
import json
import logging
import requests
from typing import List, Dict, Any, Optional
from bs4 import BeautifulSoup
from datetime import datetime
import re
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

logger = logging.getLogger(__name__)


class ComprehensiveLoanScraper:
    """68å®¶é‡‘èæœºæ„å®Œæ•´çˆ¬è™«ç³»ç»Ÿ"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        })
        
        # åŠ è½½é‡‘èæœºæ„é…ç½®
        config_path = os.path.join(
            os.path.dirname(__file__),
            '../data/malaysia_financial_institutions.json'
        )
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
        
        # æ±‡æ€»æ‰€æœ‰é‡‘èæœºæ„
        self.institutions = []
        for category in ['commercial_banks', 'islamic_banks', 'development_banks', 
                        'digital_banks', 'p2p_platforms', 'non_bank_credit']:
            self.institutions.extend(self.config.get(category, []))
        
        self.loan_products = self.config['loan_products']
        
        logger.info(f"âœ… åŠ è½½äº† {len(self.institutions)} å®¶é‡‘èæœºæ„")
        logger.info(f"âœ… æ”¯æŒ {len(self.loan_products)} ç§è´·æ¬¾äº§å“ç±»å‹")
    
    def extract_rate(self, text: str) -> Optional[str]:
        """ä»æ–‡æœ¬ä¸­æå–åˆ©ç‡"""
        if not text:
            return None
        # åŒ¹é…ç™¾åˆ†æ¯”æ ¼å¼ï¼š6.88%, 3.5%, etc.
        match = re.search(r'(\d+\.?\d*)%', str(text))
        if match:
            return match.group(0)
        # åŒ¹é…åŸºå‡†åˆ©ç‡æ ¼å¼ï¼šBR + 2.5%, BLR - 1.0%, etc.
        match = re.search(r'(BR|BLR|SBR)\s*[\+\-]\s*(\d+\.?\d*)%?', str(text), re.IGNORECASE)
        if match:
            return f"{match.group(1)} {match.group(2)}%"
        return None
    
    def scrape_institution(self, institution: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        çˆ¬å–å•ä¸ªé‡‘èæœºæ„çš„æ‰€æœ‰è´·æ¬¾äº§å“
        
        Args:
            institution: {
                'code': 'maybank',
                'name': 'Malayan Banking Berhad',
                'website': 'https://www.maybank.com.my',
                'type': 'commercial'
            }
        
        Returns:
            [
                {
                    'source': 'maybank',
                    'bank': 'Maybank',
                    'product': 'Home Loan Flexi',
                    'type': 'HOME',
                    'rate': '3.75%',
                    'summary': '...',
                    'url': 'https://...',
                    'institution_type': 'commercial',
                    'pulled_at': '2025-11-09T...'
                },
                ...
            ]
        """
        products = []
        
        try:
            base_url = institution['website']
            
            # å¸¸è§è´·æ¬¾äº§å“é¡µé¢è·¯å¾„æ¨¡å¼
            loan_paths = [
                '/personal/loans',
                '/loans',
                '/financing',
                '/products/loans',
                '/en/personal/loans',
                '/loan-products',
                '/personal-loan',
                '/home-loan',
                '/business-loan',
            ]
            
            for path in loan_paths:
                try:
                    url = f"{base_url}{path}"
                    response = self.session.get(url, timeout=10, allow_redirects=True)
                    
                    if response.status_code == 200:
                        soup = BeautifulSoup(response.text, 'html.parser')
                        
                        # æŸ¥æ‰¾è´·æ¬¾äº§å“æ ‡é¢˜
                        titles = soup.find_all(['h1', 'h2', 'h3', 'h4'], 
                                               string=re.compile(r'loan|financing|kredit', re.IGNORECASE))
                        
                        for title in titles[:10]:  # é™åˆ¶æ¯ä¸ªé¡µé¢æœ€å¤š10ä¸ªäº§å“
                            product_name = title.get_text(strip=True)
                            
                            # åˆ¤æ–­è´·æ¬¾ç±»å‹
                            product_type = self.classify_loan_type(product_name)
                            
                            # æŸ¥æ‰¾åˆ©ç‡ä¿¡æ¯
                            parent = title.find_parent(['div', 'section', 'article'])
                            rate_text = None
                            if parent:
                                rate_elem = parent.find(text=re.compile(r'\d+\.?\d*%'))
                                rate_text = self.extract_rate(rate_elem) if rate_elem else None
                            
                            product = {
                                'source': institution['code'],
                                'bank': institution['name'],
                                'product': product_name,
                                'type': product_type,
                                'rate': rate_text or 'Contact Bank',
                                'summary': f"è¯·è®¿é—® {institution['name']} å®˜ç½‘äº†è§£è¯¦æƒ…",
                                'url': url,
                                'institution_type': institution['type'],
                                'pulled_at': datetime.now().isoformat()
                            }
                            products.append(product)
                        
                        if len(products) > 0:
                            logger.info(f"âœ… {institution['name']}: æ‰¾åˆ° {len(products)} ä¸ªäº§å“")
                            break  # æ‰¾åˆ°äº§å“åè·³å‡ºè·¯å¾„å¾ªç¯
                    
                    time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«
                    
                except Exception as e:
                    logger.debug(f"âš ï¸ {institution['name']} è·¯å¾„ {path} å¤±è´¥: {e}")
                    continue
            
            if len(products) == 0:
                logger.warning(f"âš ï¸ {institution['name']}: æœªæ‰¾åˆ°è´·æ¬¾äº§å“")
            
        except Exception as e:
            logger.error(f"âŒ {institution['name']} æ•´ä½“çˆ¬å–å¤±è´¥: {e}")
        
        return products
    
    def classify_loan_type(self, product_name: str) -> str:
        """æ ¹æ®äº§å“åç§°åˆ†ç±»è´·æ¬¾ç±»å‹"""
        product_lower = product_name.lower()
        
        # æˆ¿è´·
        if any(kw in product_lower for kw in ['home', 'housing', 'mortgage', 'property', 'rumah']):
            return 'HOME'
        
        # å†èèµ„
        if any(kw in product_lower for kw in ['refinance', 'refin', 'refinancing']):
            return 'REFINANCE'
        
        # å€ºåŠ¡æ•´åˆ
        if any(kw in product_lower for kw in ['debt consolidation', 'consolidation', 'debt']):
            return 'DEBT_CONSOLIDATION'
        
        # ä¼ä¸š/SMEè´·æ¬¾
        if any(kw in product_lower for kw in ['business', 'sme', 'commercial', 'enterprise', 'perniagaan']):
            return 'BUSINESS'
        
        # ä¸ªäººè´·æ¬¾ï¼ˆé»˜è®¤ï¼‰
        if any(kw in product_lower for kw in ['personal', 'peribadi', 'cash']):
            return 'PERSONAL'
        
        # å…¶ä»–
        return 'OTHER'
    
    def scrape_all_institutions(self, max_workers: int = 10) -> List[Dict[str, Any]]:
        """
        å¹¶å‘çˆ¬å–æ‰€æœ‰68å®¶é‡‘èæœºæ„
        
        Args:
            max_workers: å¹¶å‘çº¿ç¨‹æ•°ï¼ˆé»˜è®¤10ï¼‰
        
        Returns:
            æ‰€æœ‰çˆ¬å–åˆ°çš„è´·æ¬¾äº§å“åˆ—è¡¨
        """
        all_products = []
        
        logger.info(f"ğŸš€ å¼€å§‹å¹¶å‘çˆ¬å– {len(self.institutions)} å®¶é‡‘èæœºæ„...")
        logger.info(f"âš™ï¸ ä½¿ç”¨ {max_workers} ä¸ªå¹¶å‘çº¿ç¨‹")
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_inst = {
                executor.submit(self.scrape_institution, inst): inst 
                for inst in self.institutions
            }
            
            # æ”¶é›†ç»“æœ
            completed = 0
            for future in as_completed(future_to_inst):
                inst = future_to_inst[future]
                try:
                    products = future.result()
                    all_products.extend(products)
                    completed += 1
                    
                    if completed % 10 == 0:
                        logger.info(f"ğŸ“Š è¿›åº¦: {completed}/{len(self.institutions)} å®¶æœºæ„å·²å®Œæˆ")
                    
                except Exception as e:
                    logger.error(f"âŒ {inst['name']} å¤„ç†å¤±è´¥: {e}")
        
        logger.info(f"ğŸ‰ çˆ¬å–å®Œæˆï¼å…±è·å– {len(all_products)} ä¸ªè´·æ¬¾äº§å“")
        
        # æŒ‰é“¶è¡Œç±»å‹åˆ†ç»„ç»Ÿè®¡
        stats = {}
        for product in all_products:
            inst_type = product['institution_type']
            stats[inst_type] = stats.get(inst_type, 0) + 1
        
        logger.info("ğŸ“ˆ æŒ‰æœºæ„ç±»å‹ç»Ÿè®¡:")
        for inst_type, count in stats.items():
            logger.info(f"  - {inst_type}: {count} ä¸ªäº§å“")
        
        return all_products
    
    def scrape_by_category(self, category: str) -> List[Dict[str, Any]]:
        """
        æŒ‰æœºæ„ç±»åˆ«çˆ¬å–ï¼ˆç”¨äºåˆ†æ‰¹æµ‹è¯•ï¼‰
        
        Args:
            category: 'commercial_banks', 'islamic_banks', 'digital_banks', etc.
        """
        institutions = self.config.get(category, [])
        logger.info(f"ğŸ¯ çˆ¬å–ç±»åˆ«: {category} ({len(institutions)} å®¶æœºæ„)")
        
        products = []
        for inst in institutions:
            inst_products = self.scrape_institution(inst)
            products.extend(inst_products)
            time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
        
        return products
    
    def validate_products(self, products: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """éªŒè¯å’Œæ¸…æ´—äº§å“æ•°æ®"""
        valid_products = []
        required_fields = ['source', 'bank', 'product', 'type']
        
        for product in products:
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            if all(product.get(field) for field in required_fields):
                # æ ‡å‡†åŒ–åˆ©ç‡æ ¼å¼
                if product.get('rate') and '%' not in product['rate']:
                    product['rate'] = f"{product['rate']}%"
                
                # ç¡®ä¿æœ‰summary
                if not product.get('summary'):
                    product['summary'] = f"è¯·è®¿é—® {product['bank']} å®˜ç½‘äº†è§£è¯¦æƒ…"
                
                # ç¡®ä¿æœ‰URL
                if not product.get('url'):
                    product['url'] = 'N/A'
                
                valid_products.append(product)
            else:
                missing = [f for f in required_fields if not product.get(f)]
                logger.warning(f"âš ï¸ äº§å“æ•°æ®ä¸å®Œæ•´ï¼ˆç¼ºå°‘ {missing}ï¼‰ï¼Œè·³è¿‡: {product.get('product', 'Unknown')}")
        
        logger.info(f"âœ… éªŒè¯é€šè¿‡ {len(valid_products)}/{len(products)} ä¸ªäº§å“")
        return valid_products
    
    def export_to_csv(self, products: List[Dict[str, Any]], filename: str = 'malaysia_loans.csv'):
        """å¯¼å‡ºä¸ºCSVæ–‡ä»¶"""
        import csv
        
        if not products:
            logger.warning("âš ï¸ æ²¡æœ‰äº§å“å¯å¯¼å‡º")
            return
        
        fieldnames = list(products[0].keys())
        
        with open(filename, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(products)
        
        logger.info(f"âœ… å·²å¯¼å‡º {len(products)} ä¸ªäº§å“åˆ° {filename}")


# å…¨å±€å•ä¾‹
comprehensive_scraper = ComprehensiveLoanScraper()

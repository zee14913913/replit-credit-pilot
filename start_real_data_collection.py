"""
å¯åŠ¨çœŸå®è´·æ¬¾æ•°æ®é‡‡é›†
ä»68å®¶é©¬æ¥è¥¿äºšé‡‘èæœºæ„è·å–çœŸå®æ•°æ®
åŒ…å«12ä¸ªè¯¦ç»†å­—æ®µ
"""
import sys
import os
sys.path.insert(0, '/home/runner/workspace')

import sqlite3
import logging
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å¯¼å…¥é‡‡é›†æ¨¡å—
from accounting_app.services.bnm_api_client import bnm_client
from accounting_app.services.comprehensive_loan_scraper import comprehensive_scraper
from accounting_app.services.detailed_loan_scraper import detailed_scraper

DB_PATH = os.getenv("LOANS_DB_PATH", "/home/runner/loans.db")


def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“ï¼ˆ12ä¸ªå­—æ®µï¼‰"""
    logger.info("ğŸ“Š åˆå§‹åŒ–æ•°æ®åº“...")
    
    con = sqlite3.connect(DB_PATH)
    cur = con.cursor()
    
    # åˆ›å»ºè¯¦ç»†äº§å“è¡¨
    cur.execute("""
        CREATE TABLE IF NOT EXISTS loan_products_detailed(
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            company TEXT,
            loan_type TEXT,
            product_name TEXT,
            required_doc TEXT,
            features TEXT,
            benefits TEXT,
            fees_charges TEXT,
            tenure TEXT,
            rate TEXT,
            application_form_url TEXT,
            product_disclosure_url TEXT,
            terms_conditions_url TEXT,
            preferred_customer_type TEXT,
            institution_type TEXT,
            source_url TEXT,
            pulled_at TEXT
        )
    """)
    
    con.commit()
    con.close()
    logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")


def collect_bnm_rates():
    """é‡‡é›†BNMå®˜æ–¹åˆ©ç‡"""
    logger.info("=" * 80)
    logger.info("ğŸ“Š ç¬¬1æ­¥ï¼šé‡‡é›†BNMå®˜æ–¹åˆ©ç‡æ•°æ®")
    logger.info("=" * 80)
    
    try:
        rates = bnm_client.get_all_rates()
        logger.info(f"âœ… BNMæ•°æ®é‡‡é›†æˆåŠŸ")
        logger.info(f"   æ•°æ®æ¥æº: {', '.join(rates.get('data_sources', []))}")
        
        if rates.get('opr'):
            logger.info(f"   OPR: {rates['opr'].get('opr', 'N/A')}%")
        
        return rates
    except Exception as e:
        logger.error(f"âŒ BNMæ•°æ®é‡‡é›†å¤±è´¥: {e}")
        return None


def collect_basic_products():
    """
    é‡‡é›†åŸºç¡€äº§å“ä¿¡æ¯ï¼ˆ7ä¸ªå­—æ®µï¼‰
    å¿«é€Ÿè·å–æ‰€æœ‰68å®¶æœºæ„çš„äº§å“åˆ—è¡¨
    """
    logger.info("=" * 80)
    logger.info("ğŸ•·ï¸ ç¬¬2æ­¥ï¼šé‡‡é›†åŸºç¡€äº§å“ä¿¡æ¯ï¼ˆ68å®¶æœºæ„ï¼‰")
    logger.info("=" * 80)
    
    try:
        # å¹¶å‘çˆ¬å–æ‰€æœ‰æœºæ„
        products = comprehensive_scraper.scrape_all_institutions(max_workers=10)
        
        # éªŒè¯æ•°æ®
        valid_products = comprehensive_scraper.validate_products(products)
        
        logger.info(f"âœ… åŸºç¡€äº§å“ä¿¡æ¯é‡‡é›†å®Œæˆ")
        logger.info(f"   æ€»è®¡: {len(valid_products)} ä¸ªäº§å“")
        
        # æŒ‰æœºæ„ç±»å‹ç»Ÿè®¡
        stats = {}
        for p in valid_products:
            inst_type = p.get('institution_type', 'unknown')
            stats[inst_type] = stats.get(inst_type, 0) + 1
        
        logger.info("   æŒ‰æœºæ„ç±»å‹åˆ†å¸ƒ:")
        for inst_type, count in sorted(stats.items(), key=lambda x: -x[1]):
            logger.info(f"     - {inst_type}: {count} ä¸ªäº§å“")
        
        return valid_products
    except Exception as e:
        logger.error(f"âŒ åŸºç¡€äº§å“é‡‡é›†å¤±è´¥: {e}")
        return []


def enrich_product_details(basic_products):
    """
    å¢å¼ºäº§å“è¯¦ç»†ä¿¡æ¯ï¼ˆ12ä¸ªå­—æ®µï¼‰
    ä¸ºæ¯ä¸ªäº§å“è¡¥å……å®Œæ•´çš„è¯¦ç»†å­—æ®µ
    """
    logger.info("=" * 80)
    logger.info("ğŸ” ç¬¬3æ­¥ï¼šå¢å¼ºäº§å“è¯¦ç»†ä¿¡æ¯ï¼ˆ12ä¸ªå­—æ®µï¼‰")
    logger.info("=" * 80)
    
    detailed_products = []
    total = len(basic_products)
    
    logger.info(f"âš™ï¸ å¼€å§‹æ·±åº¦çˆ¬å– {total} ä¸ªäº§å“çš„è¯¦ç»†ä¿¡æ¯...")
    logger.info("â±ï¸ é¢„è®¡æ—¶é—´: 15-30åˆ†é’Ÿ")
    logger.info("")
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = []
        
        for product in basic_products:
            # æäº¤ä»»åŠ¡ï¼šçˆ¬å–æ¯ä¸ªäº§å“çš„è¯¦ç»†é¡µé¢
            future = executor.submit(
                detailed_scraper.scrape_product_details,
                bank_name=product['bank'],
                product_url=product.get('url', product.get('source_url', '')),
                loan_type=product['type'],
                institution_type=product.get('institution_type', 'commercial')
            )
            futures.append(future)
        
        # æ”¶é›†ç»“æœ
        completed = 0
        for future in as_completed(futures):
            try:
                detailed_product = future.result()
                detailed_products.append(detailed_product)
                
                completed += 1
                if completed % 10 == 0:
                    logger.info(f"ğŸ“Š è¿›åº¦: {completed}/{total} ({completed*100//total}%)")
                    
            except Exception as e:
                logger.error(f"âŒ äº§å“è¯¦æƒ…æå–å¤±è´¥: {e}")
                completed += 1
    
    logger.info(f"âœ… è¯¦ç»†ä¿¡æ¯é‡‡é›†å®Œæˆ: {len(detailed_products)}/{total}")
    return detailed_products


def save_to_database(products):
    """ä¿å­˜åˆ°æ•°æ®åº“"""
    logger.info("=" * 80)
    logger.info("ğŸ’¾ ç¬¬4æ­¥ï¼šä¿å­˜æ•°æ®åˆ°æ•°æ®åº“")
    logger.info("=" * 80)
    
    if not products:
        logger.warning("âš ï¸ æ²¡æœ‰äº§å“æ•°æ®å¯ä¿å­˜")
        return
    
    con = sqlite3.connect(DB_PATH)
    cur = con.cursor()
    
    # æ¸…ç©ºæ—§æ•°æ®
    cur.execute("DELETE FROM loan_products_detailed")
    logger.info("   æ¸…ç©ºæ—§æ•°æ®...")
    
    # æ’å…¥æ–°æ•°æ®
    timestamp = datetime.now().isoformat()
    
    insert_sql = """
        INSERT INTO loan_products_detailed(
            company, loan_type, product_name, required_doc, features, benefits,
            fees_charges, tenure, rate, application_form_url, product_disclosure_url,
            terms_conditions_url, preferred_customer_type, institution_type,
            source_url, pulled_at
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """
    
    items = [
        (
            p['company'],
            p['loan_type'],
            p['product_name'],
            p['required_doc'],
            p['features'],
            p['benefits'],
            p['fees_charges'],
            p['tenure'],
            p['rate'],
            p.get('application_form_url'),
            p.get('product_disclosure_url'),
            p.get('terms_conditions_url'),
            p['preferred_customer_type'],
            p['institution_type'],
            p.get('source_url'),
            timestamp
        )
        for p in products
    ]
    
    cur.executemany(insert_sql, items)
    con.commit()
    con.close()
    
    logger.info(f"âœ… æˆåŠŸä¿å­˜ {len(products)} ä¸ªäº§å“åˆ°æ•°æ®åº“")


def export_to_csv(products):
    """å¯¼å‡ºä¸ºCSVæ–‡ä»¶"""
    logger.info("=" * 80)
    logger.info("ğŸ“¤ ç¬¬5æ­¥ï¼šå¯¼å‡ºCSVå¤‡ä»½")
    logger.info("=" * 80)
    
    import csv
    
    if not products:
        logger.warning("âš ï¸ æ²¡æœ‰äº§å“æ•°æ®å¯å¯¼å‡º")
        return
    
    filename = f"/home/runner/malaysia_loans_detailed_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    
    fieldnames = [
        'company', 'loan_type', 'product_name', 'required_doc', 'features',
        'benefits', 'fees_charges', 'tenure', 'rate', 'application_form_url',
        'product_disclosure_url', 'terms_conditions_url', 'preferred_customer_type',
        'institution_type', 'source_url', 'pulled_at'
    ]
    
    with open(filename, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(products)
    
    logger.info(f"âœ… CSVæ–‡ä»¶å·²å¯¼å‡º: {filename}")


def main():
    """ä¸»æµç¨‹"""
    logger.info("")
    logger.info("â•”" + "=" * 78 + "â•—")
    logger.info("â•‘" + " " * 15 + "é©¬æ¥è¥¿äºš68å®¶é‡‘èæœºæ„çœŸå®è´·æ¬¾æ•°æ®é‡‡é›†" + " " * 22 + "â•‘")
    logger.info("â•‘" + " " * 25 + "12ä¸ªè¯¦ç»†å­—æ®µå®Œæ•´ç‰ˆ" + " " * 27 + "â•‘")
    logger.info("â•š" + "=" * 78 + "â•")
    logger.info("")
    
    start_time = datetime.now()
    
    # æ­¥éª¤1ï¼šåˆå§‹åŒ–æ•°æ®åº“
    init_database()
    logger.info("")
    
    # æ­¥éª¤2ï¼šé‡‡é›†BNMå®˜æ–¹åˆ©ç‡
    bnm_rates = collect_bnm_rates()
    logger.info("")
    
    # æ­¥éª¤3ï¼šé‡‡é›†åŸºç¡€äº§å“ä¿¡æ¯
    basic_products = collect_basic_products()
    logger.info("")
    
    if not basic_products:
        logger.error("âŒ åŸºç¡€äº§å“é‡‡é›†å¤±è´¥ï¼Œæµç¨‹ä¸­æ­¢")
        return
    
    # æ­¥éª¤4ï¼šå¢å¼ºè¯¦ç»†ä¿¡æ¯
    detailed_products = enrich_product_details(basic_products)
    logger.info("")
    
    # æ­¥éª¤5ï¼šä¿å­˜åˆ°æ•°æ®åº“
    save_to_database(detailed_products)
    logger.info("")
    
    # æ­¥éª¤6ï¼šå¯¼å‡ºCSV
    export_to_csv(detailed_products)
    logger.info("")
    
    # å®Œæˆ
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    
    logger.info("=" * 80)
    logger.info("ğŸ‰ æ•°æ®é‡‡é›†å®Œæˆï¼")
    logger.info("=" * 80)
    logger.info(f"   æ€»è€—æ—¶: {duration:.1f} ç§’ ({duration/60:.1f} åˆ†é’Ÿ)")
    logger.info(f"   äº§å“æ€»æ•°: {len(detailed_products)}")
    logger.info(f"   æ•°æ®åº“: {DB_PATH}")
    logger.info("")
    logger.info("ğŸ“Š ç°åœ¨å¯ä»¥é€šè¿‡ä»¥ä¸‹APIè®¿é—®æ•°æ®:")
    logger.info("   GET /loans/detailed/")
    logger.info("   GET /loans/detailed/export.csv")
    logger.info("   GET /loans/detailed/stats/summary")
    logger.info("")


if __name__ == '__main__':
    main()

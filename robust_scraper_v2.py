#!/usr/bin/env python3
"""
å¼ºåŒ–ç‰ˆçˆ¬è™«V2 - å¤„ç†å¤§å‹é“¶è¡Œç½‘ç«™ï¼Œè¶…æ—¶ä¿æŠ¤ï¼Œè‡ªåŠ¨è·³è¿‡é—®é¢˜ç½‘ç«™
"""
import csv, time, requests, psycopg2, os, re
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
from psycopg2.extras import execute_values
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, TimeoutError
from functools import partial

DATABASE_URL = os.getenv('DATABASE_URL')
CSV_FILE = "/home/runner/workspace/attached_assets/New é©¬æ¥è¥¿äºšè´·æ¬¾æœºæ„ä¸å¹³å°å…¨å®˜ç½‘_å®Œæ•´ç‰ˆ.csv_1762667764316.csv"

print("=" * 80)
print("ğŸš€ å¼ºåŒ–ç‰ˆçˆ¬è™«V2 å¯åŠ¨")
print("=" * 80)

def get_completed():
    con = psycopg2.connect(DATABASE_URL)
    cur = con.cursor()
    cur.execute("SELECT DISTINCT company FROM loan_products_ultimate")
    completed = set(r[0] for r in cur.fetchall())
    cur.close()
    con.close()
    return completed

def load_institutions():
    inst = []
    with open(CSV_FILE, 'r', encoding='utf-8') as f:
        reader = csv.reader(f)
        next(reader)
        for idx, row in enumerate(reader, 1):
            if len(row) >= 2:
                inst.append({'order': idx, 'name': row[0].strip(), 'url': row[1].strip()})
    return inst

def classify_product(text):
    t = text.lower()
    if any(k in t for k in ['credit card', 'kad kredit', 'visa', 'mastercard', 'amex']): 
        return 'CREDIT_CARD'
    elif any(k in t for k in ['home', 'housing', 'mortgage', 'property', 'rumah']): 
        return 'HOME_LOAN'
    elif any(k in t for k in ['personal loan', 'cash loan', 'pinjaman peribadi']): 
        return 'PERSONAL_LOAN'
    elif any(k in t for k in ['car', 'auto', 'vehicle', 'hire purchase']): 
        return 'CAR_LOAN'
    elif any(k in t for k in ['business', 'sme', 'commercial', 'enterprise']): 
        return 'SME_LOAN'
    elif any(k in t for k in ['fixed deposit', 'fd', 'time deposit', 'deposit']): 
        return 'FIXED_DEPOSIT'
    elif any(k in t for k in ['overdraft', 'od', 'working capital']): 
        return 'OVERDRAFT'
    elif any(k in t for k in ['refinance', 'refinancing', 'refi']): 
        return 'REFINANCE'
    else: 
        return 'OTHER'

def scrape_single_url(session, full_url, company_name, timeout=10):
    """çˆ¬å–å•ä¸ªURLï¼Œå¸¦è¶…æ—¶ä¿æŠ¤"""
    products = []
    try:
        r = session.get(full_url, timeout=timeout)
        if r.status_code != 200:
            return products
        
        soup = BeautifulSoup(r.text, 'html.parser')
        
        # æŸ¥æ‰¾äº§å“æ ‡é¢˜ (h1-h4, strong, bold text)
        for tag in soup.find_all(['h1', 'h2', 'h3', 'h4', 'strong', 'b'])[:50]:
            txt = tag.get_text(strip=True)
            
            # è¿‡æ»¤æ¡ä»¶ï¼šé•¿åº¦åˆé€‚ & åŒ…å«äº§å“å…³é”®è¯
            if 5 < len(txt) < 150:
                keywords = ['card', 'loan', 'deposit', 'financing', 'kredit', 'pinjaman', 'simpanan', 'kad']
                if any(k in txt.lower() for k in keywords):
                    # æå–åˆ©ç‡
                    rate = 'è¯·è”ç³»é“¶è¡Œ'
                    rate_match = re.search(r'(\d+\.?\d*)\s*%', soup.get_text()[:5000])
                    if rate_match:
                        rate = rate_match.group(0)
                    
                    products.append({
                        'company': company_name,
                        'name': txt,
                        'type': classify_product(txt),
                        'rate': rate,
                        'url': full_url
                    })
        
    except Exception:
        pass
    
    return products

def scrape_company_with_timeout(order, name, url, max_timeout=120):
    """çˆ¬å–å•ä¸ªå…¬å¸ï¼Œæ€»è¶…æ—¶é™åˆ¶"""
    print(f"\n[{order}/67] {name}")
    print(f"   ğŸŒ {url}")
    
    start_time = time.time()
    products = []
    
    try:
        session = requests.Session()
        session.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
        }
        
        # åŠ¨æ€ç”ŸæˆURLè·¯å¾„
        paths = [
            '/', '/personal', '/business', '/sme', '/corporate',
            '/personal/cards', '/personal/loans', '/personal/deposits', '/personal/financing',
            '/business/loans', '/business/financing', '/sme/loans', '/sme/financing',
            '/cards', '/credit-cards', '/debit-cards',
            '/loans', '/financing', '/personal-loan', '/home-loan', '/mortgage',
            '/fixed-deposit', '/time-deposit', '/deposits',
            '/overdraft', '/working-capital',
            '/products', '/products/cards', '/products/loans', '/products/deposits',
            '/banking/personal', '/banking/business',
        ]
        
        # éå†è·¯å¾„ï¼Œä½†é™åˆ¶æ€»æ—¶é—´
        for p in paths[:40]:
            if time.time() - start_time > max_timeout:
                print(f"   â±ï¸  è¶…æ—¶({max_timeout}ç§’)ï¼Œåœæ­¢çˆ¬å–")
                break
            
            full_url = urljoin(url, p)
            prods = scrape_single_url(session, full_url, name, timeout=8)
            products.extend(prods)
            time.sleep(0.15)
        
        # å»é‡
        seen = set()
        unique = []
        for p in products:
            key = f"{p['company']}|{p['name']}"
            if key not in seen and len(p['name']) > 5:
                seen.add(key)
                unique.append(p)
        
        elapsed = time.time() - start_time
        print(f"   âœ… {len(unique)} ä¸ªäº§å“ (ç”¨æ—¶{elapsed:.1f}ç§’)")
        return unique
        
    except Exception as e:
        print(f"   âŒ é”™è¯¯: {str(e)[:60]}")
        return []

def save_to_db(products):
    if not products:
        return 0
    
    con = psycopg2.connect(DATABASE_URL)
    cur = con.cursor()
    
    sql = """
        INSERT INTO loan_products_ultimate(
            company, loan_type, product_name, required_doc, features, benefits,
            fees_charges, tenure, rate, application_form_url, product_disclosure_url,
            terms_conditions_url, preferred_customer_type, source_url, scraped_at
        ) VALUES %s
        ON CONFLICT (company, product_name) DO NOTHING
    """
    
    items = [(
        p['company'], p['type'], p['name'], 'è¯·è®¿é—®é“¶è¡Œå®˜ç½‘äº†è§£è¯¦æƒ…', 
        'è¯·è®¿é—®é“¶è¡Œå®˜ç½‘äº†è§£è¯¦æƒ…', 'è¯·è®¿é—®é“¶è¡Œå®˜ç½‘äº†è§£è¯¦æƒ…',
        'è¯·è”ç³»é“¶è¡Œ', 'è¯·è”ç³»é“¶è¡Œ', p['rate'], '', '', '', 
        'æ‰€æœ‰å®¢æˆ·', p['url'], datetime.now()
    ) for p in products]
    
    execute_values(cur, sql, items)
    con.commit()
    inserted = cur.rowcount
    cur.close()
    con.close()
    return inserted

# ä¸»ç¨‹åº
completed = get_completed()
all_inst = load_institutions()
remaining = [inst for inst in all_inst if inst['name'] not in completed]

print(f"\nğŸ“Š å·²å®Œæˆ: {len(completed)} å®¶")
print(f"ğŸ“‹ æ€»æœºæ„: {len(all_inst)} å®¶")
print(f"ğŸ¯ å‰©ä½™: {len(remaining)} å®¶\n")

total_new_products = 0
total_new_companies = 0
failed_companies = []

for inst in remaining:
    try:
        products = scrape_company_with_timeout(inst['order'], inst['name'], inst['url'], max_timeout=120)
        
        if products:
            inserted = save_to_db(products)
            total_new_products += len(products)
            total_new_companies += 1
            print(f"   ğŸ’¾ å·²ä¿å­˜{inserted}ä¸ªäº§å“")
        else:
            failed_companies.append(inst['name'])
            print(f"   âš ï¸  æ— äº§å“æ•°æ®")
        
        time.sleep(1)
        
    except Exception as e:
        failed_companies.append(inst['name'])
        print(f"   âŒ å¼‚å¸¸: {str(e)[:50]}")

print("\n" + "=" * 80)
print(f"ğŸ‰ çˆ¬å–å®Œæˆï¼")
print(f"   æ–°å¢äº§å“: {total_new_products} ä¸ª")
print(f"   æ–°å¢å…¬å¸: {total_new_companies} å®¶")
print("=" * 80)

# æœ€ç»ˆç»Ÿè®¡
con = psycopg2.connect(DATABASE_URL)
cur = con.cursor()
cur.execute("SELECT COUNT(*), COUNT(DISTINCT company) FROM loan_products_ultimate")
result = cur.fetchone()
if result:
    total, companies = result
    print(f"\nğŸ“Š æ•°æ®åº“æ€»è®¡: {total} ä¸ªäº§å“ï¼Œ{companies} å®¶å…¬å¸")

cur.execute("""
    SELECT loan_type, COUNT(*) as cnt 
    FROM loan_products_ultimate 
    GROUP BY loan_type 
    ORDER BY cnt DESC
""")
print("\nğŸ“ˆ äº§å“ç±»å‹åˆ†å¸ƒ:")
for row in cur.fetchall():
    print(f"   {row[0]:20s}: {row[1]:4d}")

cur.close()
con.close()

if failed_companies:
    print(f"\nâš ï¸  æ— æ•°æ®çš„å…¬å¸ ({len(failed_companies)}):")
    for name in failed_companies[:10]:
        print(f"   - {name}")
    if len(failed_companies) > 10:
        print(f"   ... è¿˜æœ‰{len(failed_companies)-10}å®¶")

print("\nâœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
print("=" * 80)

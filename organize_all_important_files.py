#!/usr/bin/env python3
"""
æ•´ç†æ‰€æœ‰é‡è¦æ–‡ä»¶ - æ‰§è¡Œæ–¹æ¡ˆ1+2+3
"""
import os
import shutil
import json
import sqlite3
from datetime import datetime

def create_directories():
    """åˆ›å»ºç›®å½•ç»“æ„"""
    dirs = [
        'lee_e_kai_data/database_backup',
        'lee_e_kai_data/statements',
        'lee_e_kai_data/reports',
        'parser_system/extractors',
        'parser_system/parsers',
        'parser_system/config',
        'parser_system/docs',
        'parser_system/services',
    ]
    
    for d in dirs:
        os.makedirs(d, exist_ok=True)
        print(f"âœ… åˆ›å»ºç›®å½•: {d}")

def backup_lee_data():
    """æ–¹æ¡ˆ1: å¤‡ä»½LEE E KAIæ•°æ®"""
    print("\n" + "=" * 120)
    print("æ–¹æ¡ˆ1: å¤‡ä»½LEE E KAIæ•°æ®")
    print("=" * 120)
    
    # å¤‡ä»½æ•°æ®åº“
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    db_backup = f'lee_e_kai_data/database_backup/smart_loan_manager_backup_{timestamp}.db'
    shutil.copy2('db/smart_loan_manager.db', db_backup)
    print(f"âœ… æ•°æ®åº“å¤‡ä»½: {db_backup}")
    
    # å¯¼å‡ºå®¢æˆ·æ•°æ®æ‘˜è¦
    conn = sqlite3.connect('db/smart_loan_manager.db')
    cursor = conn.cursor()
    
    summary = {
        'backup_date': timestamp,
        'customer': {},
        'credit_cards': [],
        'statements': []
    }
    
    # å®¢æˆ·ä¿¡æ¯
    cursor.execute("SELECT id, name, customer_code, email FROM customers WHERE id = 18")
    cust = cursor.fetchone()
    if cust:
        summary['customer'] = {
            'id': cust[0],
            'name': cust[1],
            'customer_code': cust[2],
            'email': cust[3]
        }
    
    # ä¿¡ç”¨å¡ä¿¡æ¯
    cursor.execute("SELECT id, bank_name, card_number_last4 FROM credit_cards WHERE customer_id = 18")
    for card in cursor.fetchall():
        summary['credit_cards'].append({
            'id': card[0],
            'bank': card[1],
            'last4': card[2]
        })
    
    # å¯¹è´¦å•ä¿¡æ¯
    cursor.execute("""
        SELECT s.id, s.statement_date, cc.bank_name, s.file_path
        FROM statements s
        JOIN credit_cards cc ON s.card_id = cc.id
        WHERE cc.customer_id = 18
    """)
    for stmt in cursor.fetchall():
        summary['statements'].append({
            'id': stmt[0],
            'date': stmt[1],
            'bank': stmt[2],
            'file': stmt[3]
        })
    
    conn.close()
    
    # ä¿å­˜æ‘˜è¦
    summary_file = f'lee_e_kai_data/customer_data_summary_{timestamp}.json'
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    print(f"âœ… æ•°æ®æ‘˜è¦: {summary_file}")
    
    # åˆ›å»ºREADME
    readme = f"""# LEE E KAI å®¢æˆ·æ•°æ®å­˜æ¡£

## å¤‡ä»½æ—¶é—´
{timestamp}

## å®¢æˆ·ä¿¡æ¯
- å§“å: {summary['customer']['name']}
- å®¢æˆ·ç¼–å·: {summary['customer']['customer_code']}
- é‚®ç®±: {summary['customer']['email']}

## ä¿¡ç”¨å¡
- å…±{len(summary['credit_cards'])}å¼ ä¿¡ç”¨å¡

## å¯¹è´¦å•
- å…±{len(summary['statements'])}æ¡å¯¹è´¦å•è®°å½•

## ç›®å½•ç»“æ„
```
lee_e_kai_data/
â”œâ”€â”€ database_backup/    æ•°æ®åº“å¤‡ä»½æ–‡ä»¶
â”œâ”€â”€ statements/         PDFå¯¹è´¦å•æ–‡ä»¶
â”œâ”€â”€ reports/           å®¢æˆ·æŠ¥å‘Š
â””â”€â”€ customer_data_summary_*.json  æ•°æ®æ‘˜è¦
```
"""
    
    with open('lee_e_kai_data/README.md', 'w', encoding='utf-8') as f:
        f.write(readme)
    print(f"âœ… READMEæ–‡æ¡£: lee_e_kai_data/README.md")

def organize_parser_system():
    """æ–¹æ¡ˆ2: æ•´åˆParserç³»ç»Ÿ"""
    print("\n" + "=" * 120)
    print("æ–¹æ¡ˆ2: æ•´åˆParserç³»ç»Ÿ")
    print("=" * 120)
    
    # å¤åˆ¶æå–å™¨
    if os.path.exists('pdf_field_extractor.py'):
        shutil.copy2('pdf_field_extractor.py', 'parser_system/extractors/pdf_field_extractor.py')
        print("âœ… å¤åˆ¶: pdf_field_extractor.py -> parser_system/extractors/")
    
    # å¤åˆ¶parsersç›®å½•
    if os.path.exists('parsers'):
        for file in os.listdir('parsers'):
            src = os.path.join('parsers', file)
            dst = os.path.join('parser_system/parsers', file)
            if os.path.isfile(src):
                shutil.copy2(src, dst)
                print(f"âœ… å¤åˆ¶: {src} -> {dst}")
    
    # å¤åˆ¶servicesä¸­çš„parseræ–‡ä»¶
    if os.path.exists('services'):
        parser_services = [
            'bank_specific_parser.py',
            'bank_specific_parsers.py',
            'fallback_parser.py',
            'intelligent_parser.py',
            'ai_pdf_parser.py',
            'docparser_service.py'
        ]
        for file in parser_services:
            src = os.path.join('services', file)
            if os.path.exists(src):
                dst = os.path.join('parser_system/services', file)
                shutil.copy2(src, dst)
                print(f"âœ… å¤åˆ¶: {src} -> {dst}")
    
    # å¤åˆ¶é…ç½®æ–‡ä»¶
    config_files = [
        'bank_parser_templates.json',
        'bank_parser_templates_13banks_16fields.json',
        'parser_field_keywords.json',
        'pdf_parser_config.py'
    ]
    for file in config_files:
        src = os.path.join('config', file)
        if os.path.exists(src):
            dst = os.path.join('parser_system/config', file)
            shutil.copy2(src, dst)
            print(f"âœ… å¤åˆ¶: {src} -> {dst}")
    
    # å¤åˆ¶æ–‡æ¡£
    if os.path.exists('docparser_templates'):
        for file in os.listdir('docparser_templates'):
            src = os.path.join('docparser_templates', file)
            if os.path.isfile(src) and file.endswith('.md'):
                dst = os.path.join('parser_system/docs', file)
                shutil.copy2(src, dst)
                print(f"âœ… å¤åˆ¶æ–‡æ¡£: {src} -> {dst}")
    
    # åˆ›å»ºParserç³»ç»ŸREADME
    readme = """# Parser System å®Œæ•´å¤‡ä»½

## ç›®å½•ç»“æ„

```
parser_system/
â”œâ”€â”€ extractors/          PDFå­—æ®µæå–å™¨
â”‚   â””â”€â”€ pdf_field_extractor.py (40KB)
â”œâ”€â”€ parsers/             é“¶è¡Œç‰¹å®šParser
â”‚   â”œâ”€â”€ hsbc_parser.py
â”‚   â””â”€â”€ hsbc_ocr_parser.py
â”œâ”€â”€ services/            ParseræœåŠ¡å±‚
â”‚   â”œâ”€â”€ bank_specific_parser.py
â”‚   â”œâ”€â”€ bank_specific_parsers.py
â”‚   â”œâ”€â”€ fallback_parser.py
â”‚   â”œâ”€â”€ intelligent_parser.py
â”‚   â”œâ”€â”€ ai_pdf_parser.py
â”‚   â””â”€â”€ docparser_service.py
â”œâ”€â”€ config/              é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ bank_parser_templates.json (34KB)
â”‚   â”œâ”€â”€ bank_parser_templates_13banks_16fields.json
â”‚   â”œâ”€â”€ parser_field_keywords.json
â”‚   â””â”€â”€ pdf_parser_config.py
â””â”€â”€ docs/                Parseræ–‡æ¡£
    â”œâ”€â”€ PARSER_FIELD_RULES.md
    â”œâ”€â”€ CREATE_PARSERS_GUIDE.md
    â””â”€â”€ QUICK_SETUP_5MIN.md
```

## åŠŸèƒ½è¯´æ˜

### æå–å™¨ (extractors/)
- **pdf_field_extractor.py**: æ ¸å¿ƒPDFå­—æ®µæå–å¼•æ“ï¼Œæ”¯æŒ13å®¶é©¬æ¥è¥¿äºšé“¶è¡Œ

### Parser (parsers/)
- é“¶è¡Œç‰¹å®šçš„è§£æå™¨ï¼Œå¤„ç†å„é“¶è¡ŒPDFæ ¼å¼å·®å¼‚

### æœåŠ¡å±‚ (services/)
- æä¾›ç»Ÿä¸€çš„parseræ¥å£å’Œæ™ºèƒ½è§£æç­–ç•¥

### é…ç½® (config/)
- é“¶è¡Œæ¨¡æ¿é…ç½®å’Œè§£æè§„åˆ™

### æ–‡æ¡£ (docs/)
- Parserç³»ç»Ÿä½¿ç”¨æŒ‡å—å’Œå­—æ®µè§„åˆ™
"""
    
    with open('parser_system/README.md', 'w', encoding='utf-8') as f:
        f.write(readme)
    print(f"âœ… READMEæ–‡æ¡£: parser_system/README.md")

def clean_i18n_examples():
    """æ–¹æ¡ˆ3: æ¸…ç†i18nç¤ºä¾‹æ•°æ®"""
    print("\n" + "=" * 120)
    print("æ–¹æ¡ˆ3: æ¸…ç†i18nç¤ºä¾‹å®¢æˆ·æ•°æ®")
    print("=" * 120)
    
    customer_keywords = [
        'cheok_jun_yoon', 'chang_choon_chow', 'teo_yok_chu', 
        'yeo_chee_wang', 'tan_zee_liang', 'galaxy'
    ]
    
    for lang_file in ['static/i18n/zh.json', 'static/i18n/en.json']:
        if not os.path.exists(lang_file):
            continue
        
        # å¤‡ä»½åŸæ–‡ä»¶
        backup = lang_file + '.backup'
        shutil.copy2(lang_file, backup)
        
        with open(lang_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # åˆ é™¤åŒ…å«å®¢æˆ·åç§°çš„key
        keys_to_delete = []
        for key in data.keys():
            if any(keyword in key.lower() for keyword in customer_keywords):
                keys_to_delete.append(key)
        
        for key in keys_to_delete:
            del data[key]
        
        # ä¿å­˜æ¸…ç†åçš„æ–‡ä»¶
        with open(lang_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… {lang_file}: åˆ é™¤{len(keys_to_delete)}ä¸ªç¤ºä¾‹å®¢æˆ·keyï¼Œå¤‡ä»½åˆ°{backup}")

def main():
    print("=" * 120)
    print("æ•´ç†æ‰€æœ‰é‡è¦æ–‡ä»¶ - æ‰§è¡Œæ–¹æ¡ˆ1+2+3")
    print("=" * 120)
    
    # åˆ›å»ºç›®å½•ç»“æ„
    create_directories()
    
    # æ‰§è¡Œä¸‰ä¸ªæ–¹æ¡ˆ
    backup_lee_data()
    organize_parser_system()
    clean_i18n_examples()
    
    print("\n" + "=" * 120)
    print("æ•´ç†å®Œæˆï¼")
    print("=" * 120)
    print("\nåˆ›å»ºçš„ç›®å½•:")
    print("  ğŸ“ lee_e_kai_data/        - LEE E KAIå®¢æˆ·æ•°æ®å¤‡ä»½")
    print("  ğŸ“ parser_system/         - Parserç³»ç»Ÿå®Œæ•´å¤‡ä»½")
    print("\næ¸…ç†å®Œæˆ:")
    print("  âœ… static/i18n/zh.json    - å·²åˆ é™¤ç¤ºä¾‹å®¢æˆ·æ•°æ®")
    print("  âœ… static/i18n/en.json    - å·²åˆ é™¤ç¤ºä¾‹å®¢æˆ·æ•°æ®")
    print("=" * 120)

if __name__ == '__main__':
    main()

"""
Google Document AI é“¶è¡Œè´¦å•è§£ææœåŠ¡
ç”¨é€”ï¼šä½¿ç”¨Google Document AIè§£æé©¬æ¥è¥¿äºšé“¶è¡Œä¿¡ç”¨å¡è´¦å•PDF
å‡†ç¡®åº¦ï¼š98-99.9%
"""
import os
import json
import logging
from typing import Dict, List, Optional, Any
from pathlib import Path
from datetime import datetime
from google.cloud import documentai_v1 as documentai
from google.oauth2 import service_account

logger = logging.getLogger(__name__)


class GoogleDocumentAIService:
    """Google Document AI APIå®¢æˆ·ç«¯"""
    
    def __init__(
        self, 
        service_account_json: Optional[str] = None,
        project_id: Optional[str] = None,
        location: Optional[str] = None,
        processor_id: Optional[str] = None
    ):
        """
        åˆå§‹åŒ–Google Document AIæœåŠ¡
        
        Args:
            service_account_json: Service Account JSONå†…å®¹æˆ–æ–‡ä»¶è·¯å¾„
            project_id: Google Cloudé¡¹ç›®ID
            location: Processorä½ç½®ï¼ˆå¦‚ï¼šasia-southeast1ï¼‰
            processor_id: Document AI Processor ID
        """
        # è·å–é…ç½®
        self.project_id = project_id or os.getenv('GOOGLE_PROJECT_ID')
        self.location = location or os.getenv('GOOGLE_LOCATION', 'asia-southeast1')
        self.processor_id = processor_id or os.getenv('GOOGLE_PROCESSOR_ID')
        
        if not self.project_id:
            raise ValueError("GOOGLE_PROJECT_IDæœªé…ç½®ï¼")
        
        if not self.processor_id:
            raise ValueError("GOOGLE_PROCESSOR_IDæœªé…ç½®ï¼")
        
        # è®¾ç½®è®¤è¯
        json_content = service_account_json or os.getenv('GOOGLE_SERVICE_ACCOUNT_JSON')
        
        if json_content:
            # å°è¯•è§£æJSON
            try:
                if json_content.startswith('{'):
                    # ç›´æ¥æ˜¯JSONå­—ç¬¦ä¸²
                    credentials_info = json.loads(json_content)
                elif os.path.exists(json_content):
                    # æ˜¯æ–‡ä»¶è·¯å¾„
                    with open(json_content, 'r') as f:
                        credentials_info = json.load(f)
                else:
                    credentials_info = json.loads(json_content)
                
                self.credentials = service_account.Credentials.from_service_account_info(
                    credentials_info
                )
            except Exception as e:
                logger.warning(f"Service Account JSONè§£æå¤±è´¥: {e}")
                self.credentials = None
        else:
            # å°è¯•ä½¿ç”¨é»˜è®¤è®¤è¯
            logger.info("æœªæä¾›Service Account JSONï¼Œå°è¯•ä½¿ç”¨é»˜è®¤è®¤è¯")
            self.credentials = None
        
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        try:
            if self.credentials:
                self.client = documentai.DocumentProcessorServiceClient(
                    credentials=self.credentials
                )
            else:
                # ä½¿ç”¨é»˜è®¤è®¤è¯ï¼ˆä»GOOGLE_APPLICATION_CREDENTIALSç¯å¢ƒå˜é‡ï¼‰
                self.client = documentai.DocumentProcessorServiceClient()
            
            logger.info("âœ… Google Document AIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            logger.info(f"   Project: {self.project_id}")
            logger.info(f"   Location: {self.location}")
            logger.info(f"   Processor: {self.processor_id}")
        
        except Exception as e:
            logger.error(f"âŒ å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    @property
    def processor_name(self) -> str:
        """è·å–å®Œæ•´çš„Processoråç§°"""
        return self.client.processor_path(
            self.project_id,
            self.location,
            self.processor_id
        )
    
    def parse_pdf(self, pdf_path: str) -> Dict[str, Any]:
        """
        è§£æPDFæ–‡æ¡£
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
        
        Returns:
            Dict: è§£æç»“æœ
        """
        try:
            pdf_path_obj = Path(pdf_path)
            
            if not pdf_path_obj.exists():
                raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
            
            if not pdf_path_obj.suffix.lower() == '.pdf':
                raise ValueError(f"ä»…æ”¯æŒPDFæ–‡ä»¶: {pdf_path_obj.suffix}")
            
            logger.info(f"ğŸ“„ æ­£åœ¨è§£æPDF: {pdf_path_obj.name}")
            
            # è¯»å–PDF
            with open(pdf_path, 'rb') as f:
                pdf_content = f.read()
            
            # æ„å»ºè¯·æ±‚
            raw_document = documentai.RawDocument(
                content=pdf_content,
                mime_type='application/pdf'
            )
            
            request = documentai.ProcessRequest(
                name=self.processor_name,
                raw_document=raw_document
            )
            
            # è°ƒç”¨API
            result = self.client.process_document(request=request)
            
            logger.info(f"âœ… è§£ææˆåŠŸ: {pdf_path_obj.name}")
            
            # è½¬æ¢ä¸ºå­—å…¸
            return self._document_to_dict(result.document)
        
        except Exception as e:
            logger.error(f"âŒ è§£æPDFå¤±è´¥: {e}")
            raise
    
    def _document_to_dict(self, document) -> Dict[str, Any]:
        """å°†Documentå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸"""
        result = {
            'text': document.text,
            'pages': len(document.pages),
            'entities': [],
            'tables': []
        }
        
        # æå–entities
        for entity in document.entities:
            result['entities'].append({
                'type': entity.type_,
                'mention_text': entity.mention_text,
                'confidence': entity.confidence,
                'normalized_value': getattr(entity.normalized_value, 'text', None) if hasattr(entity, 'normalized_value') else None
            })
        
        # æå–è¡¨æ ¼
        for page in document.pages:
            for table in page.tables:
                table_data = {
                    'header_rows': [],
                    'body_rows': []
                }
                
                for row in table.header_rows:
                    table_data['header_rows'].append([
                        self._get_text(document.text, cell.layout) 
                        for cell in row.cells
                    ])
                
                for row in table.body_rows:
                    table_data['body_rows'].append([
                        self._get_text(document.text, cell.layout)
                        for cell in row.cells
                    ])
                
                result['tables'].append(table_data)
        
        return result
    
    def _get_text(self, doc_text: str, layout) -> str:
        """ä»layoutæå–æ–‡æœ¬"""
        try:
            if not layout.text_anchor or not layout.text_anchor.text_segments:
                return ''
            
            segments = []
            for segment in layout.text_anchor.text_segments:
                start = int(segment.start_index) if hasattr(segment, 'start_index') else 0
                end = int(segment.end_index) if hasattr(segment, 'end_index') else len(doc_text)
                segments.append(doc_text[start:end])
            
            return ''.join(segments).strip()
        except:
            return ''
    
    def extract_bank_statement_fields(self, parsed_doc: Dict) -> Dict[str, Any]:
        """
        ä»è§£æç»“æœä¸­æå–é“¶è¡Œè´¦å•å­—æ®µ
        
        Args:
            parsed_doc: parse_pdfè¿”å›çš„å­—å…¸
        
        Returns:
            Dict: æ ‡å‡†åŒ–çš„è´¦å•å­—æ®µ
        """
        fields = {
            'card_number': None,
            'statement_date': None,
            'cardholder_name': None,
            'previous_balance': 0.0,
            'total_credit': 0.0,
            'total_debit': 0.0,
            'current_balance': 0.0,
            'minimum_payment': 0.0,
            'payment_due_date': None,
            'transactions': []
        }
        
        # ä»entitiesæå–å­—æ®µ
        for entity in parsed_doc.get('entities', []):
            entity_type = entity['type'].lower()
            mention_text = entity['mention_text']
            
            if 'card' in entity_type or 'account' in entity_type:
                # æå–å¡å·å4ä½
                import re
                match = re.search(r'\d{4}', mention_text)
                if match:
                    fields['card_number'] = match.group()
            
            elif 'date' in entity_type:
                if 'statement' in entity_type or 'billing' in entity_type:
                    fields['statement_date'] = mention_text
                elif 'due' in entity_type or 'payment' in entity_type:
                    fields['payment_due_date'] = mention_text
            
            elif 'name' in entity_type or 'cardholder' in entity_type:
                fields['cardholder_name'] = mention_text
            
            elif 'balance' in entity_type:
                amount = self._parse_amount(mention_text)
                if 'previous' in entity_type or 'last' in entity_type:
                    fields['previous_balance'] = amount
                elif 'current' in entity_type or 'new' in entity_type:
                    fields['current_balance'] = amount
            
            elif 'payment' in entity_type:
                amount = self._parse_amount(mention_text)
                if 'minimum' in entity_type:
                    fields['minimum_payment'] = amount
                else:
                    fields['total_credit'] = amount
            
            elif 'purchase' in entity_type or 'debit' in entity_type:
                fields['total_debit'] = self._parse_amount(mention_text)
        
        # ä»è¡¨æ ¼æå–äº¤æ˜“
        fields['transactions'] = self._extract_transactions_from_tables(
            parsed_doc.get('tables', [])
        )
        
        logger.info(f"âœ… æå–å­—æ®µå®Œæˆï¼Œäº¤æ˜“æ•°: {len(fields['transactions'])}")
        
        return fields
    
    def _parse_amount(self, text: str) -> float:
        """è§£æé‡‘é¢"""
        try:
            import re
            cleaned = re.sub(r'[^\d.]', '', text)
            return float(cleaned) if cleaned else 0.0
        except:
            return 0.0
    
    def _extract_transactions_from_tables(self, tables: List[Dict]) -> List[Dict]:
        """ä»è¡¨æ ¼ä¸­æå–äº¤æ˜“"""
        transactions = []
        
        for table in tables:
            for row in table.get('body_rows', []):
                if len(row) >= 3:
                    trans = {
                        'date': row[0],
                        'description': row[1],
                        'amount': self._parse_amount(row[2]),
                        'type': 'CR' if 'CR' in row[2] or 'PAYMENT' in row[1].upper() else 'DR'
                    }
                    transactions.append(trans)
        
        return transactions
    
    def batch_parse_pdfs(
        self, 
        pdf_folder: str, 
        output_folder: Optional[str] = None
    ) -> List[Dict]:
        """æ‰¹é‡è§£æPDF"""
        results = []
        pdf_path = Path(pdf_folder)
        
        if not pdf_path.exists():
            logger.error(f"æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {pdf_folder}")
            return results
        
        pdf_files = list(pdf_path.glob("**/*.pdf"))
        
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡è§£æ {len(pdf_files)} ä¸ªPDF...")
        
        for i, pdf_file in enumerate(pdf_files, 1):
            try:
                logger.info(f"\nã€{i}/{len(pdf_files)}ã€‘{pdf_file.name}")
                
                parsed_doc = self.parse_pdf(str(pdf_file))
                fields = self.extract_bank_statement_fields(parsed_doc)
                
                result = {
                    'filename': pdf_file.name,
                    'success': True,
                    'fields': fields,
                    'raw_data': parsed_doc
                }
                
                results.append(result)
                
                if output_folder:
                    output_path = Path(output_folder) / f"{pdf_file.stem}_parsed.json"
                    output_path.parent.mkdir(parents=True, exist_ok=True)
                    
                    with open(output_path, 'w', encoding='utf-8') as f:
                        json.dump(result, f, ensure_ascii=False, indent=2)
                    
                    logger.info(f"ğŸ’¾ ä¿å­˜: {output_path.name}")
            
            except Exception as e:
                logger.error(f"âŒ è§£æå¤±è´¥: {e}")
                results.append({
                    'filename': pdf_file.name,
                    'success': False,
                    'error': str(e)
                })
        
        success_count = sum(1 for r in results if r.get('success'))
        logger.info(f"\nğŸ‰ å®Œæˆï¼æˆåŠŸ: {success_count}/{len(pdf_files)}")
        
        return results


def test_google_document_ai():
    """æµ‹è¯•æœåŠ¡"""
    try:
        service = GoogleDocumentAIService()
        
        print("="*80)
        print("Google Document AI æµ‹è¯•")
        print("="*80)
        print(f"\nâœ… Project: {service.project_id}")
        print(f"âœ… Processor: {service.processor_id}")
        
        test_file = 'docparser_templates/sample_pdfs/1_AMBANK.pdf'
        
        if os.path.exists(test_file):
            print(f"\nğŸ“„ æµ‹è¯•æ–‡ä»¶: {test_file}")
            parsed = service.parse_pdf(test_file)
            fields = service.extract_bank_statement_fields(parsed)
            
            print(f"\nğŸ“Š ç»“æœ:")
            print(f"   å¡å·: {fields.get('card_number')}")
            print(f"   æ—¥æœŸ: {fields.get('statement_date')}")
            print(f"   ä¸ŠæœŸç»“ä½™: RM {fields.get('previous_balance'):.2f}")
            print(f"   æœ¬æœŸç»“ä½™: RM {fields.get('current_balance'):.2f}")
            print(f"   äº¤æ˜“æ•°: {len(fields.get('transactions', []))}")
            print("\nâœ… æµ‹è¯•é€šè¿‡ï¼")
        
        return True
    
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == '__main__':
    test_google_document_ai()

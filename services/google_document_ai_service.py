"""
Google Document AI é“¶è¡Œè´¦å•è§£ææœåŠ¡
ç”¨é€”ï¼šä½¿ç”¨Google Document AIè§£æé©¬æ¥è¥¿äºšé“¶è¡Œä¿¡ç”¨å¡è´¦å•PDF
å‡†ç¡®åº¦ï¼š98-99.9%
"""
import os
import json
import logging
from typing import Dict, List, Optional, Any
from pathlib import Path
from datetime import datetime
from google.cloud import documentai_v1 as documentai
from google.oauth2 import service_account

logger = logging.getLogger(__name__)


class GoogleDocumentAIService:
    """Google Document AI APIå®¢æˆ·ç«¯"""
    
    def __init__(
        self, 
        service_account_json: Optional[str] = None,
        project_id: Optional[str] = None,
        location: Optional[str] = None,
        processor_id: Optional[str] = None
    ):
        """
        åˆå§‹åŒ–Google Document AIæœåŠ¡
        
        Args:
            service_account_json: Service Account JSONå†…å®¹æˆ–æ–‡ä»¶è·¯å¾„
            project_id: Google Cloudé¡¹ç›®ID
            location: Processorä½ç½®ï¼ˆå¦‚ï¼šasia-southeast1ï¼‰
            processor_id: Document AI Processor ID
        """
        # è·å–é…ç½®
        self.project_id = project_id or os.getenv('GOOGLE_PROJECT_ID')
        self.location = location or os.getenv('GOOGLE_LOCATION', 'us')
        self.processor_id = processor_id or os.getenv('GOOGLE_PROCESSOR_ID')
        
        if not self.project_id:
            raise ValueError("GOOGLE_PROJECT_IDæœªé…ç½®ï¼")
        
        if not self.processor_id:
            raise ValueError("GOOGLE_PROCESSOR_IDæœªé…ç½®ï¼")
        
        # è®¾ç½®è®¤è¯
        json_content = service_account_json or os.getenv('GOOGLE_SERVICE_ACCOUNT_JSON')
        
        if json_content:
            # å°è¯•è§£æJSON
            try:
                if json_content.startswith('{'):
                    # ç›´æ¥æ˜¯JSONå­—ç¬¦ä¸²
                    credentials_info = json.loads(json_content)
                elif os.path.exists(json_content):
                    # æ˜¯æ–‡ä»¶è·¯å¾„
                    with open(json_content, 'r') as f:
                        credentials_info = json.load(f)
                else:
                    credentials_info = json.loads(json_content)
                
                self.credentials = service_account.Credentials.from_service_account_info(
                    credentials_info
                )
            except Exception as e:
                logger.warning(f"Service Account JSONè§£æå¤±è´¥: {e}")
                self.credentials = None
        else:
            # å°è¯•ä½¿ç”¨é»˜è®¤è®¤è¯
            logger.info("æœªæä¾›Service Account JSONï¼Œå°è¯•ä½¿ç”¨é»˜è®¤è®¤è¯")
            self.credentials = None
        
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        try:
            if self.credentials:
                self.client = documentai.DocumentProcessorServiceClient(
                    credentials=self.credentials
                )
            else:
                # ä½¿ç”¨é»˜è®¤è®¤è¯ï¼ˆä»GOOGLE_APPLICATION_CREDENTIALSç¯å¢ƒå˜é‡ï¼‰
                self.client = documentai.DocumentProcessorServiceClient()
            
            logger.info("âœ… Google Document AIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            logger.info(f"   Project: {self.project_id}")
            logger.info(f"   Location: {self.location}")
            logger.info(f"   Processor: {self.processor_id}")
        
        except Exception as e:
            logger.error(f"âŒ å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    @property
    def processor_name(self) -> str:
        """è·å–å®Œæ•´çš„Processoråç§°"""
        return self.client.processor_path(
            self.project_id,
            self.location,
            self.processor_id
        )
    
    def parse_pdf(self, pdf_path: str) -> Dict[str, Any]:
        """
        è§£æPDFæ–‡æ¡£
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
        
        Returns:
            Dict: è§£æç»“æœ
        """
        try:
            pdf_path_obj = Path(pdf_path)
            
            if not pdf_path_obj.exists():
                raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
            
            if not pdf_path_obj.suffix.lower() == '.pdf':
                raise ValueError(f"ä»…æ”¯æŒPDFæ–‡ä»¶: {pdf_path_obj.suffix}")
            
            logger.info(f"ğŸ“„ æ­£åœ¨è§£æPDF: {pdf_path_obj.name}")
            
            # è¯»å–PDF
            with open(pdf_path, 'rb') as f:
                pdf_content = f.read()
            
            # æ„å»ºè¯·æ±‚
            raw_document = documentai.RawDocument(
                content=pdf_content,
                mime_type='application/pdf'
            )
            
            request = documentai.ProcessRequest(
                name=self.processor_name,
                raw_document=raw_document
            )
            
            # è°ƒç”¨API
            result = self.client.process_document(request=request)
            
            logger.info(f"âœ… è§£ææˆåŠŸ: {pdf_path_obj.name}")
            
            # è½¬æ¢ä¸ºå­—å…¸
            return self._document_to_dict(result.document)
        
        except Exception as e:
            logger.error(f"âŒ è§£æPDFå¤±è´¥: {e}")
            raise
    
    def _document_to_dict(self, document) -> Dict[str, Any]:
        """å°†Documentå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸"""
        result = {
            'text': document.text,
            'pages': len(document.pages),
            'entities': [],
            'tables': []
        }
        
        # æå–entities
        for entity in document.entities:
            result['entities'].append({
                'type': entity.type_,
                'mention_text': entity.mention_text,
                'confidence': entity.confidence,
                'normalized_value': getattr(entity.normalized_value, 'text', None) if hasattr(entity, 'normalized_value') else None
            })
        
        # æå–è¡¨æ ¼
        for page in document.pages:
            for table in page.tables:
                table_data = {
                    'header_rows': [],
                    'body_rows': []
                }
                
                for row in table.header_rows:
                    table_data['header_rows'].append([
                        self._get_text(document.text, cell.layout) 
                        for cell in row.cells
                    ])
                
                for row in table.body_rows:
                    table_data['body_rows'].append([
                        self._get_text(document.text, cell.layout)
                        for cell in row.cells
                    ])
                
                result['tables'].append(table_data)
        
        return result
    
    def _get_text(self, doc_text: str, layout) -> str:
        """ä»layoutæå–æ–‡æœ¬"""
        try:
            if not layout.text_anchor or not layout.text_anchor.text_segments:
                return ''
            
            segments = []
            for segment in layout.text_anchor.text_segments:
                start = int(segment.start_index) if hasattr(segment, 'start_index') else 0
                end = int(segment.end_index) if hasattr(segment, 'end_index') else len(doc_text)
                segments.append(doc_text[start:end])
            
            return ''.join(segments).strip()
        except:
            return ''
    
    def extract_bank_statement_fields(self, parsed_doc: Dict, bank_name: str = None) -> Dict[str, Any]:
        """
        ä»è§£æç»“æœä¸­æå–é“¶è¡Œè´¦å•å­—æ®µï¼ˆä½¿ç”¨é“¶è¡Œä¸“ç”¨æ¨¡ç‰ˆï¼‰
        
        Args:
            parsed_doc: parse_pdfè¿”å›çš„å­—å…¸
            bank_name: é“¶è¡Œåç§°ï¼ˆå¯é€‰ï¼Œä¼šè‡ªåŠ¨æ£€æµ‹ï¼‰
        
        Returns:
            Dict: æ ‡å‡†åŒ–çš„è´¦å•å­—æ®µ
        """
        from services.bank_specific_parsers import parse_with_bank_template
        
        text = parsed_doc.get('text', '')
        
        try:
            # ä½¿ç”¨é“¶è¡Œä¸“ç”¨æ¨¡ç‰ˆè§£æ
            logger.info("ğŸ¯ ä½¿ç”¨é“¶è¡Œä¸“ç”¨æ¨¡ç‰ˆè§£æå™¨")
            info, transactions = parse_with_bank_template(text, bank_name)
            
            # è½¬æ¢ä¸ºfieldsæ ¼å¼
            fields = {
                'card_number': info.get('card_last4'),
                'statement_date': info.get('statement_date'),
                'cardholder_name': info.get('customer_name'),
                'previous_balance': info.get('previous_balance', 0.0),
                'current_balance': info.get('total_amount_due', 0.0),
                'minimum_payment': info.get('minimum_payment', 0.0),
                'payment_due_date': info.get('payment_due_date'),
                'credit_limit': info.get('credit_limit', 0.0),
                'available_credit': info.get('available_credit', 0.0),
                'reward_points': info.get('reward_points', '0'),
                'transactions': transactions
            }
            
            logger.info(f"âœ… é“¶è¡Œæ¨¡ç‰ˆæå–å®Œæˆï¼š{len(transactions)}ç¬”äº¤æ˜“")
            
            return fields
            
        except Exception as e:
            logger.warning(f"âš ï¸ é“¶è¡Œæ¨¡ç‰ˆè§£æå¤±è´¥: {e}ï¼Œå°è¯•é€šç”¨æ–¹æ³•")
            
            # Fallback to original generic extraction
            return self._extract_fields_generic(parsed_doc)
    
    def _extract_fields_generic(self, parsed_doc: Dict) -> Dict[str, Any]:
        """é€šç”¨å­—æ®µæå–æ–¹æ³•ï¼ˆfallbackï¼‰"""
        import re
        
        text = parsed_doc.get('text', '')
        
        fields = {
            'card_number': None,
            'statement_date': None,
            'cardholder_name': None,
            'previous_balance': 0.0,
            'total_credit': 0.0,
            'total_debit': 0.0,
            'current_balance': 0.0,
            'minimum_payment': 0.0,
            'payment_due_date': None,
            'transactions': []
        }
        
        # æå–å¡å·ï¼ˆ16ä½ï¼Œç©ºæ ¼åˆ†éš”ï¼‰
        card_pattern = r'(\d{4}\s+\d{4}\s+\d{4}\s+\d{4})'
        card_match = re.search(card_pattern, text)
        if card_match:
            full_card = card_match.group(1).replace(' ', '')
            fields['card_number'] = full_card[-4:]
        
        # æå–è´¦å•æ—¥æœŸ
        date_patterns = [
            r'Statement Date[^\n]*?(\d{1,2}\s+[A-Z]{3}\s+\d{2})',
            r'Tarikh Penyata[^\n]*?(\d{1,2}\s+[A-Z]{3}\s+\d{2})',
            r'STATEMENT DATE[^\n]*?(\d{1,2}\s+[A-Z]{3}\s+\d{4})'
        ]
        for pattern in date_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                fields['statement_date'] = match.group(1)
                break
        
        # æå–ä¸ŠæœŸç»“ä½™
        prev_patterns = [
            r'Previous Balance[^\n]*?RM\s*([\d,]+\.\d{2})',
            r'Baki Terdahulu[^\n]*?RM\s*([\d,]+\.\d{2})',
            r'PREVIOUS BALANCE[^\n]*?RM\s*([\d,]+\.\d{2})',
            r'Last Balance[^\n]*?RM\s*([\d,]+\.\d{2})'
        ]
        for pattern in prev_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                fields['previous_balance'] = self._parse_amount(match.group(1))
                break
        
        # æå–æœ¬æœŸç»“ä½™
        curr_patterns = [
            r'Current Balance[^\n]*?RM\s*([\d,]+\.\d{2})',
            r'Baki Semasa[^\n]*?RM\s*([\d,]+\.\d{2})',
            r'New Balance[^\n]*?RM\s*([\d,]+\.\d{2})',
            r'CURRENT BALANCE[^\n]*?RM\s*([\d,]+\.\d{2})'
        ]
        for pattern in curr_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                fields['current_balance'] = self._parse_amount(match.group(1))
                break
        
        # æå–æœ€ä½è¿˜æ¬¾é¢
        min_patterns = [
            r'Minimum Payment[^\n]*?RM\s*([\d,]+\.\d{2})',
            r'Bayaran Minimum[^\n]*?RM\s*([\d,]+\.\d{2})',
            r'MINIMUM PAYMENT[^\n]*?RM\s*([\d,]+\.\d{2})'
        ]
        for pattern in min_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                fields['minimum_payment'] = self._parse_amount(match.group(1))
                break
        
        # ä»è¡¨æ ¼æå–äº¤æ˜“
        fields['transactions'] = self._extract_transactions_from_tables(
            parsed_doc.get('tables', [])
        )
        
        # å¦‚æœè¡¨æ ¼æ²¡æœ‰äº¤æ˜“ï¼Œå°è¯•ä»æ–‡æœ¬æå–
        if len(fields['transactions']) == 0:
            fields['transactions'] = self._extract_transactions_from_text(text)
        
        logger.info(f"âœ… é€šç”¨æ–¹æ³•æå–å®Œæˆï¼Œäº¤æ˜“æ•°: {len(fields['transactions'])}")
        
        return fields
    
    def _parse_amount(self, text: str) -> float:
        """è§£æé‡‘é¢"""
        try:
            import re
            cleaned = re.sub(r'[^\d.]', '', text)
            return float(cleaned) if cleaned else 0.0
        except:
            return 0.0
    
    def _extract_transactions_from_tables(self, tables: List[Dict]) -> List[Dict]:
        """
        ä»è¡¨æ ¼ä¸­æå–äº¤æ˜“ï¼ˆæ”¯æŒç‹¬ç«‹DR/CRåˆ—å¸ƒå±€ï¼‰
        
        é©¬æ¥è¥¿äºšé“¶è¡Œè´¦å•å¸¸è§æ ¼å¼ï¼š
        - 3åˆ—ï¼šDate | Description | Amount (DR/CRæ ‡è®°)
        - 4åˆ—ï¼šDate | Description | DR | CR
        - 5åˆ—ï¼šDate | Posting Date | Description | DR | CR
        """
        transactions = []
        
        for table in tables:
            for row in table.get('body_rows', []):
                if len(row) < 3:
                    continue
                
                date_col = row[0].strip()
                
                # è¿‡æ»¤æ‰æ ‡é¢˜è¡Œ
                if date_col.lower() in ['date', 'tarikh', 'posting date', 'trans date']:
                    continue
                
                # å°è¯•æ£€æµ‹å¸ƒå±€ç±»å‹
                if len(row) >= 4:
                    # å¯èƒ½æ˜¯4åˆ—æˆ–5åˆ—å¸ƒå±€ï¼ˆç‹¬ç«‹DR/CRåˆ—ï¼‰
                    desc_idx = 1
                    dr_idx = 2
                    cr_idx = 3
                    
                    # å¦‚æœæœ‰5åˆ—ï¼Œæ£€æŸ¥ç¬¬2åˆ—æ˜¯å¦æ˜¯æ—¥æœŸï¼ˆPosting Dateï¼‰
                    if len(row) >= 5 and self._is_date(row[1].strip()):
                        desc_idx = 2
                        dr_idx = 3
                        cr_idx = 4
                    
                    desc_col = row[desc_idx].strip()
                    dr_col = row[dr_idx].strip() if dr_idx < len(row) else ''
                    cr_col = row[cr_idx].strip() if cr_idx < len(row) else ''
                    
                    # è§£æDRé‡‘é¢
                    dr_amount = self._parse_amount(dr_col)
                    if dr_amount > 0:
                        transactions.append({
                            'date': date_col,
                            'description': desc_col,
                            'amount': dr_amount,
                            'type': 'DR'
                        })
                    
                    # è§£æCRé‡‘é¢
                    cr_amount = self._parse_amount(cr_col)
                    if cr_amount > 0:
                        transactions.append({
                            'date': date_col,
                            'description': desc_col,
                            'amount': cr_amount,
                            'type': 'CR'
                        })
                
                elif len(row) == 3:
                    # 3åˆ—å¸ƒå±€ï¼šDate | Description | Amount
                    desc_col = row[1].strip()
                    amount_col = row[2].strip()
                    
                    # è§£æé‡‘é¢å’Œç±»å‹
                    amount, trans_type = self._parse_amount_with_type(amount_col)
                    
                    # æ£€æŸ¥æè¿°ä¸­çš„CRæ ‡è®°
                    if trans_type == 'DR' and ('PAYMENT' in desc_col.upper() or 'BAYARAN' in desc_col.upper()):
                        trans_type = 'CR'
                    
                    if amount > 0:
                        transactions.append({
                            'date': date_col,
                            'description': desc_col,
                            'amount': amount,
                            'type': trans_type
                        })
        
        return transactions
    
    def _is_date(self, text: str) -> bool:
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦æ˜¯æ—¥æœŸ"""
        import re
        date_patterns = [
            r'\d{1,2}\s+[A-Z]{3}',  # 01 JAN
            r'\d{1,2}/\d{1,2}',      # 01/01
            r'\d{4}-\d{2}-\d{2}'     # 2024-01-01
        ]
        for pattern in date_patterns:
            if re.match(pattern, text, re.IGNORECASE):
                return True
        return False
    
    def _parse_amount_with_type(self, text: str) -> tuple:
        """
        è§£æé‡‘é¢å’Œç±»å‹ï¼ˆä¿ç•™DR/CRææ€§ï¼‰
        
        Returns:
            (amount: float, type: str)  # type = 'DR' or 'CR'
        """
        import re
        
        # æ£€æŸ¥CRæ ‡è®°
        is_credit = 'CR' in text.upper() or text.strip().startswith('-')
        
        # æ¸…ç†å¹¶è§£æé‡‘é¢
        cleaned = re.sub(r'[^\d.]', '', text)
        amount = float(cleaned) if cleaned else 0.0
        
        return (amount, 'CR' if is_credit else 'DR')
    
    def _extract_transactions_from_text(self, text: str) -> List[Dict]:
        """ä»æ–‡æœ¬ä¸­æ™ºèƒ½æå–äº¤æ˜“ï¼ˆé€è¡Œè§£æé©¬æ¥è¥¿äºšé“¶è¡Œæ ¼å¼ï¼‰"""
        import re
        
        transactions = []
        lines = text.split('\n')
        
        # æ‰¾åˆ°äº¤æ˜“éƒ¨åˆ†çš„å¼€å§‹
        in_transaction_section = False
        
        for i, line in enumerate(lines):
            line = line.strip()
            
            # æ£€æµ‹äº¤æ˜“éƒ¨åˆ†çš„å¼€å§‹
            if 'PREVIOUS BALANCE' in line.upper():
                in_transaction_section = True
                continue
            
            # æ£€æµ‹äº¤æ˜“éƒ¨åˆ†çš„ç»“æŸ
            if in_transaction_section and ('Total Current Balance' in line or 'PAYMENT ADVICE' in line):
                break
            
            if not in_transaction_section:
                continue
            
            # åŒ¹é…æ—¥æœŸï¼ˆDD MMMï¼‰
            date_match = re.match(r'(\d{2}\s+[A-Z]{3})', line)
            
            if date_match:
                date = date_match.group(1)
                # æè¿°åœ¨åŒä¸€è¡Œæˆ–ä¸‹ä¸€è¡Œ
                description = line[len(date):].strip()
                
                # æ£€æŸ¥ä¸‹ä¸€è¡Œæ˜¯å¦æœ‰é‡‘é¢
                if i + 1 < len(lines):
                    next_line = lines[i + 1].strip()
                    amount_match = re.search(r'^([\d,]+\.\d{2})\s*(CR)?$', next_line)
                    
                    if amount_match:
                        amount = self._parse_amount(amount_match.group(1))
                        trans_type = 'CR' if amount_match.group(2) else 'DR'
                        
                        if amount > 0:
                            transactions.append({
                                'date': date,
                                'description': description or 'Transaction',
                                'amount': amount,
                                'type': trans_type
                            })
            
            # ä¹ŸåŒ¹é…æè¿°è¡Œåé¢çš„é‡‘é¢
            elif in_transaction_section and re.match(r'^[\d,]+\.\d{2}\s*(CR)?$', line):
                amount_match = re.match(r'^([\d,]+\.\d{2})\s*(CR)?$', line)
                if amount_match and i > 0:
                    amount = self._parse_amount(amount_match.group(1))
                    trans_type = 'CR' if amount_match.group(2) else 'DR'
                    description = lines[i - 1].strip()
                    
                    # é¿å…é‡å¤ï¼ˆå¦‚æœä¸Šä¸€è¡Œå·²ç»æœ‰æ—¥æœŸï¼‰
                    if not re.match(r'^\d{2}\s+[A-Z]{3}', description) and amount > 0:
                        # å°è¯•å‘å‰æŸ¥æ‰¾æ—¥æœŸ
                        date = None
                        for j in range(max(0, i - 3), i):
                            prev_line = lines[j].strip()
                            date_match = re.match(r'(\d{2}\s+[A-Z]{3})', prev_line)
                            if date_match:
                                date = date_match.group(1)
                                break
                        
                        if date and description:
                            transactions.append({
                                'date': date,
                                'description': description,
                                'amount': amount,
                                'type': trans_type
                            })
        
        return transactions
    
    def batch_parse_pdfs(
        self, 
        pdf_folder: str, 
        output_folder: Optional[str] = None
    ) -> List[Dict]:
        """æ‰¹é‡è§£æPDF"""
        results = []
        pdf_path = Path(pdf_folder)
        
        if not pdf_path.exists():
            logger.error(f"æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {pdf_folder}")
            return results
        
        pdf_files = list(pdf_path.glob("**/*.pdf"))
        
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡è§£æ {len(pdf_files)} ä¸ªPDF...")
        
        for i, pdf_file in enumerate(pdf_files, 1):
            try:
                logger.info(f"\nã€{i}/{len(pdf_files)}ã€‘{pdf_file.name}")
                
                parsed_doc = self.parse_pdf(str(pdf_file))
                fields = self.extract_bank_statement_fields(parsed_doc)
                
                result = {
                    'filename': pdf_file.name,
                    'success': True,
                    'fields': fields,
                    'raw_data': parsed_doc
                }
                
                results.append(result)
                
                if output_folder:
                    output_path = Path(output_folder) / f"{pdf_file.stem}_parsed.json"
                    output_path.parent.mkdir(parents=True, exist_ok=True)
                    
                    with open(output_path, 'w', encoding='utf-8') as f:
                        json.dump(result, f, ensure_ascii=False, indent=2)
                    
                    logger.info(f"ğŸ’¾ ä¿å­˜: {output_path.name}")
            
            except Exception as e:
                logger.error(f"âŒ è§£æå¤±è´¥: {e}")
                results.append({
                    'filename': pdf_file.name,
                    'success': False,
                    'error': str(e)
                })
        
        success_count = sum(1 for r in results if r.get('success'))
        logger.info(f"\nğŸ‰ å®Œæˆï¼æˆåŠŸ: {success_count}/{len(pdf_files)}")
        
        return results


def test_google_document_ai():
    """æµ‹è¯•æœåŠ¡"""
    try:
        service = GoogleDocumentAIService()
        
        print("="*80)
        print("Google Document AI æµ‹è¯•")
        print("="*80)
        print(f"\nâœ… Project: {service.project_id}")
        print(f"âœ… Processor: {service.processor_id}")
        
        test_file = 'docparser_templates/sample_pdfs/1_AMBANK.pdf'
        
        if os.path.exists(test_file):
            print(f"\nğŸ“„ æµ‹è¯•æ–‡ä»¶: {test_file}")
            parsed = service.parse_pdf(test_file)
            fields = service.extract_bank_statement_fields(parsed)
            
            print(f"\nğŸ“Š ç»“æœ:")
            print(f"   å¡å·: {fields.get('card_number')}")
            print(f"   æ—¥æœŸ: {fields.get('statement_date')}")
            print(f"   ä¸ŠæœŸç»“ä½™: RM {fields.get('previous_balance'):.2f}")
            print(f"   æœ¬æœŸç»“ä½™: RM {fields.get('current_balance'):.2f}")
            print(f"   äº¤æ˜“æ•°: {len(fields.get('transactions', []))}")
            print("\nâœ… æµ‹è¯•é€šè¿‡ï¼")
        
        return True
    
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == '__main__':
    test_google_document_ai()

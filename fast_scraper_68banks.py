"""
å¿«é€Ÿçˆ¬è™« - 68å®¶é‡‘èžæœºæž„å…¨é¢äº§å“æå–
ç­–ç•¥ï¼šç›´æŽ¥è®¿é—®ä¸»è¦äº§å“é¡µé¢ï¼Œæå–æ‰€æœ‰ä¿¡æ¯
ç›®æ ‡ï¼š100%å®Œæ•´æ€§ - ä¿¡ç”¨å¡ã€è´·æ¬¾ã€ODã€FDç­‰æ‰€æœ‰äº§å“
"""
import csv
import time
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import psycopg2
from psycopg2.extras import execute_values
import os
from datetime import datetime

DATABASE_URL = os.getenv('DATABASE_URL')
CSV_INPUT = "/home/runner/workspace/attached_assets/New é©¬æ¥è¥¿äºšè´·æ¬¾æœºæž„ä¸Žå¹³å°å…¨å®˜ç½‘_å®Œæ•´ç‰ˆ.csv_1762667764316.csv"

# ä¸»è¦äº§å“è·¯å¾„ï¼ˆé’ˆå¯¹æ¯å®¶é“¶è¡Œå°è¯•ï¼‰
PRODUCT_PATHS = [
    # ä¿¡ç”¨å¡
    '/personal/cards', '/personal/Cards/Credit-Cards', '/credit-cards', '/cards', '/en/cards',
    # ä¸ªäººè´·æ¬¾
    '/personal/loans', '/personal-loans', '/personal/financing', '/cash-loan',
    # æˆ¿è´·
    '/personal/home-loans', '/home-loans', '/housing-loan', '/mortgage',
    # è½¦è´·
    '/personal/car-loan', '/auto-loan', '/hire-purchase', '/vehicle-financing',
    # ä¼ä¸šè´·æ¬¾
    '/business/loans', '/business/financing', '/sme', '/sme-loans',
    # OD & FD
    '/personal/overdraft', '/overdraft', '/od',
    '/personal/fixed-deposit', '/fixed-deposit', '/fd', '/deposits',
]

def load_institutions():
    """åŠ è½½68å®¶æœºæž„"""
    institutions = []
    with open(CSV_INPUT, 'r', encoding='utf-8') as f:
        reader = csv.reader(f)
        next(reader)
        for row in reader:
            if len(row) >= 2:
                institutions.append({'name': row[0], 'website': row[1]})
    return institutions

def quick_scrape(company_name, base_url):
    """å¿«é€Ÿçˆ¬å–å•ä¸ªæœºæž„çš„æ‰€æœ‰äº§å“"""
    print(f"\nðŸ¦ {company_name}")
    print(f"   {base_url}")
    
    products = []
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0'
    })
    
    # å°è¯•æ‰€æœ‰äº§å“è·¯å¾„
    for path in PRODUCT_PATHS:
        url = urljoin(base_url, path)
        try:
            response = session.get(url, timeout=10)
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                text = soup.get_text()
                
                # ç®€å•æå–ï¼šæ‰€æœ‰åŒ…å«äº§å“å…³é”®è¯çš„æ ‡é¢˜
                for heading in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5']):
                    heading_text = heading.get_text(strip=True)
                    if len(heading_text) > 5 and len(heading_text) < 150:
                        # åˆ¤æ–­æ˜¯å¦åŒ…å«äº§å“å…³é”®è¯
                        if any(kw in heading_text.lower() for kw in ['card', 'loan', 'financing', 'deposit', 'overdraft']):
                            # æå–åˆ©çŽ‡
                            rate = 'è¯·è”ç³»é“¶è¡Œ'
                            parent = heading.find_parent(['div', 'section', 'article'])
                            if parent:
                                parent_text = parent.get_text()
                                import re
                                rate_match = re.search(r'(\d+\.?\d*)\s*%', parent_text)
                                if rate_match:
                                    rate = rate_match.group(0)
                            
                            # åˆ†ç±»
                            loan_type = 'OTHER'
                            ht_lower = heading_text.lower()
                            if 'credit card' in ht_lower or 'kad kredit' in ht_lower:
                                loan_type = 'CREDIT_CARD'
                            elif 'home' in ht_lower or 'housing' in ht_lower or 'mortgage' in ht_lower:
                                loan_type = 'HOME_LOAN'
                            elif 'personal' in ht_lower or 'cash' in ht_lower:
                                loan_type = 'PERSONAL_LOAN'
                            elif 'car' in ht_lower or 'auto' in ht_lower or 'vehicle' in ht_lower:
                                loan_type = 'CAR_LOAN'
                            elif 'business' in ht_lower or 'sme' in ht_lower:
                                loan_type = 'SME_LOAN'
                            elif 'deposit' in ht_lower or 'fd' in ht_lower:
                                loan_type = 'FIXED_DEPOSIT'
                            elif 'overdraft' in ht_lower or 'od' in ht_lower:
                                loan_type = 'OVERDRAFT'
                            
                            products.append({
                                'company': company_name,
                                'loan_type': loan_type,
                                'product_name': heading_text,
                                'rate': rate,
                                'source_url': url
                            })
                
                print(f"   âœ… {path} â†’ {len(products)} products")
                time.sleep(0.3)
        except:
            pass
    
    # åŽ»é‡
    seen = set()
    unique_products = []
    for p in products:
        key = f"{p['company']}_{p['product_name']}"
        if key not in seen:
            seen.add(key)
            unique_products.append(p)
    
    print(f"   ðŸ“¦ æ€»è®¡: {len(unique_products)} ä¸ªäº§å“")
    return unique_products

def save_to_db(products):
    """ä¿å­˜åˆ°æ•°æ®åº“"""
    if not products:
        return
    
    con = psycopg2.connect(DATABASE_URL)
    cur = con.cursor()
    
    sql = """
        INSERT INTO loan_products_ultimate(
            company, loan_type, product_name, required_doc, features, benefits,
            fees_charges, tenure, rate, application_form_url, product_disclosure_url,
            terms_conditions_url, preferred_customer_type, source_url, scraped_at
        ) VALUES %s
        ON CONFLICT (company, product_name) DO NOTHING
    """
    
    items = [(
        p['company'], p['loan_type'], p['product_name'], 'è¯·è®¿é—®é“¶è¡Œå®˜ç½‘',
        'è¯·è®¿é—®é“¶è¡Œå®˜ç½‘', 'è¯·è®¿é—®é“¶è¡Œå®˜ç½‘', 'è¯·è”ç³»é“¶è¡Œ', 'è¯·è”ç³»é“¶è¡Œ',
        p['rate'], '', '', '', 'æ‰€æœ‰å®¢æˆ·', p['source_url'], datetime.now()
    ) for p in products]
    
    execute_values(cur, sql, items)
    con.commit()
    cur.close()
    con.close()
    print(f"   ðŸ’¾ å·²ä¿å­˜åˆ°æ•°æ®åº“")

def main():
    print("=" * 80)
    print("ðŸš€ å¿«é€Ÿçˆ¬è™« - 68å®¶é‡‘èžæœºæž„å…¨é¢äº§å“æå–")
    print("=" * 80)
    
    # æ¸…ç©ºæ•°æ®åº“
    con = psycopg2.connect(DATABASE_URL)
    cur = con.cursor()
    cur.execute("TRUNCATE TABLE loan_products_ultimate RESTART IDENTITY;")
    con.commit()
    cur.close()
    con.close()
    print("âœ… æ•°æ®åº“å·²æ¸…ç©º\n")
    
    institutions = load_institutions()
    print(f"ðŸ“‹ å…± {len(institutions)} å®¶æœºæž„\n")
    
    all_products = []
    for idx, inst in enumerate(institutions, 1):
        print(f"\n[{idx}/{len(institutions)}]", end=" ")
        try:
            products = quick_scrape(inst['name'], inst['website'])
            if products:
                all_products.extend(products)
                save_to_db(products)
        except Exception as e:
            print(f"   âŒ é”™è¯¯: {e}")
        
        time.sleep(1)
    
    print("\n" + "=" * 80)
    print(f"ðŸŽ‰ å®Œæˆï¼æ€»è®¡: {len(all_products)} ä¸ªäº§å“")
    print("=" * 80)

if __name__ == '__main__':
    main()

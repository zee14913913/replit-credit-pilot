#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é©¬æ¥è¥¿äºšæ‰€æœ‰é“¶è¡Œäº§å“çˆ¬å–ä¸»è„šæœ¬
ä¸¥æ ¼æ¨¡å¼ï¼šä¸è®¸å¹»æƒ³æ•°æ®ã€å¿…é¡»è®¿é—®è¯¦æƒ…é¡µã€12å­—æ®µå®Œæ•´æå–
"""

import json
import pandas as pd
from datetime import datetime
from accounting_app.services.malaysia_bank_comprehensive_scraper import scraper

def load_financial_institutions():
    """åŠ è½½é©¬æ¥è¥¿äºšé‡‘èæœºæ„åˆ—è¡¨"""
    with open('accounting_app/data/malaysia_financial_institutions.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    all_banks = []
    all_banks.extend(data.get('commercial_banks', []))
    all_banks.extend(data.get('islamic_banks', []))
    all_banks.extend(data.get('development_banks', []))
    all_banks.extend(data.get('digital_banks', []))
    all_banks.extend(data.get('p2p_platforms', []))
    all_banks.extend(data.get('non_bank_credit', []))
    
    return all_banks

def generate_quality_report(all_products):
    """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
    print(f"\n{'='*80}")
    print("ğŸ“Š DATA QUALITY REPORT")
    print(f"{'='*80}")
    
    df = pd.DataFrame(all_products)
    total = len(df)
    
    if total == 0:
        print("âŒ NO PRODUCTS EXTRACTED")
        return
    
    no_data_count = (df == '[NO DATA FOUND]').sum().sum()
    total_cells = total * 12
    no_data_rate = (no_data_count / total_cells) * 100
    
    print(f"Total products extracted: {total}")
    print(f"Total data cells: {total_cells}")
    print(f"[NO DATA FOUND] cells: {no_data_count}")
    print(f"[NO DATA FOUND] rate: {no_data_rate:.1f}%")
    
    if total < 100:
        print(f"\nâš ï¸  WARNING: Only {total} products found (expected >100)")
    
    if no_data_rate > 20:
        print(f"âš ï¸  WARNING: [NO DATA FOUND] rate {no_data_rate:.1f}% exceeds 20%")
    
    print(f"\n{'='*80}")
    print("ğŸ“ˆ PRODUCTS BY COMPANY")
    print(f"{'='*80}")
    company_counts = df['company'].value_counts()
    for company, count in company_counts.head(10).items():
        print(f"  {company}: {count} products")
    
    print(f"\n{'='*80}")
    print("ğŸ“ˆ PRODUCTS BY TYPE")
    print(f"{'='*80}")
    type_counts = df['loan_type'].value_counts()
    for loan_type, count in type_counts.head(10).items():
        print(f"  {loan_type}: {count} products")
    
    print(f"\n{'='*80}")
    print("ğŸ¯ FIELD COMPLETION RATES")
    print(f"{'='*80}")
    for field in df.columns:
        if field in ['company', 'loan_type', 'source_url']:
            continue
        completion = ((df[field] != '[NO DATA FOUND]').sum() / total) * 100
        status = "âœ…" if completion > 50 else "âš ï¸"
        print(f"  {status} {field}: {completion:.1f}%")
    
    print(f"\n{'='*80}")
    print("ğŸ“‹ RANDOM SAMPLES FOR MANUAL VERIFICATION")
    print(f"{'='*80}")
    samples = df.sample(min(5, total))
    for idx, row in samples.iterrows():
        print(f"\n  Sample {idx+1}:")
        print(f"    Company: {row['company']}")
        print(f"    Product: {row['loan_type']}")
        print(f"    URL: {row['source_url']}")
        print(f"    Fields with data: {sum(1 for v in row.values if v != '[NO DATA FOUND]')}/12")
    
    print(f"\n{'='*80}\n")

def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*80)
    print("ğŸš€ é©¬æ¥è¥¿äºšé“¶è¡Œäº§å“å®Œæ•´çˆ¬å–ç³»ç»Ÿ")
    print("="*80)
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80 + "\n")
    
    banks = load_financial_institutions()
    print(f"âœ… åŠ è½½äº† {len(banks)} å®¶é‡‘èæœºæ„\n")
    
    all_products = []
    start_idx = scraper.progress.get('current_company_index', 0)
    
    print(f"ğŸ“ ä»ç¬¬ {start_idx + 1} å®¶å¼€å§‹...\n")
    
    for idx in range(start_idx, len(banks)):
        bank = banks[idx]
        company_name = bank.get('name', 'Unknown')
        company_url = bank.get('website', '')
        
        if not company_url:
            print(f"â­ï¸  è·³è¿‡ {company_name} - æ²¡æœ‰ç½‘å€")
            continue
        
        scraper.progress['current_company_index'] = idx
        
        try:
            products = scraper.scrape_company(company_name, company_url)
            all_products.extend(products)
            
            scraper.progress['completed_companies'].append(company_name)
            
            company_file = f"output/company_{idx:02d}_{company_name.replace(' ', '_')}.csv"
            if products:
                pd.DataFrame(products).to_csv(company_file, index=False, encoding='utf-8')
                print(f"ğŸ’¾ Saved: {company_file}")
            
        except Exception as e:
            print(f"âŒ Error processing {company_name}: {str(e)}")
            scraper.progress['failed_companies'].append({
                'company': company_name,
                'error': str(e),
                'time': datetime.now().isoformat()
            })
        
        scraper.save_progress()
        
        progress_pct = ((idx + 1) / len(banks)) * 100
        print(f"\nğŸ“Š Overall Progress: {idx + 1}/{len(banks)} ({progress_pct:.1f}%)")
        print(f"ğŸ“Š Total Products So Far: {len(all_products)}\n")
    
    final_file = 'malaysia_banks_all_products_COMPLETE.csv'
    if all_products:
        df = pd.DataFrame(all_products)
        df.to_csv(final_file, index=False, encoding='utf-8')
        print(f"\nâœ… æœ€ç»ˆæ–‡ä»¶å·²ä¿å­˜: {final_file}")
    
    generate_quality_report(all_products)
    
    print("\n" + "="*80)
    print("ğŸ‰ çˆ¬å–å®Œæˆ")
    print("="*80)
    print(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"æ€»äº§å“æ•°: {len(all_products)}")
    print(f"æˆåŠŸ: {len(scraper.progress['completed_companies'])} å®¶")
    print(f"å¤±è´¥: {len(scraper.progress['failed_companies'])} å®¶")
    print("="*80 + "\n")

if __name__ == '__main__':
    main()

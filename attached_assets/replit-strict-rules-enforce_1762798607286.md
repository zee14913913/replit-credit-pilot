# å…³é”®æŠ€å·§ï¼šé˜²æ­¢ Replit æ·»åŠ å‡æ•°æ®å’Œé—æ¼çš„å¼ºåˆ¶è§„åˆ™æ¸…å•

---

## é—®é¢˜æ ¹æºåˆ†æ

### Replit çš„å¸¸è§"è‡ªä½œèªæ˜"è¡Œä¸ºï¼š
1. **å¹»æƒ³æ•°æ®** - "è¿™ç±»è´·æ¬¾é€šå¸¸æœ‰è¿™äº›ç‰¹æ€§"â†’è‡ªå·±è¡¥æ•°æ®
2. **æµ…å±‚æŠ“å–** - åªçœ‹åˆ—è¡¨ï¼Œä¸ç‚¹è¿›è¯¦æƒ…é¡µé¢
3. **ä¸­é€”æ”¾å¼ƒ** - ç½‘ç«™å¤æ‚äº†å°±ç”¨defaultsæ›¿ä»£
4. **é—å¿˜æŒ‡ç¤º** - tokenæ¶ˆè€—è¿‡ç¨‹ä¸­é€æ¸å¿˜è®°åŸå§‹éœ€æ±‚
5. **çœç•¥å­—æ®µ** - æŸä¸ªå­—æ®µéš¾æå–å°±ä¸æå–äº†
6. **è·³è¿‡å…¬å¸** - è®¤ä¸ºå°å…¬å¸æ²¡å¿…è¦æŠ“å°±è·³è¿‡

---

## å¼ºåˆ¶æ‰§è¡Œè§„åˆ™ï¼ˆå¿…é¡»åŠ å…¥ä»£ç ä¸­ï¼‰

### è§„åˆ™1ï¼šå£°æ˜ç¦æ­¢å¹»æƒ³æ•°æ®
```python
# åœ¨è„šæœ¬æœ€é¡¶éƒ¨åŠ å…¥
STRICT_RULES = {
    'NO_SYNTHESIS': True,  # ç¦æ­¢åˆæˆ/æ¨æ–­ä»»ä½•æ•°æ®
    'NO_DEFAULT_VALUES': True,  # ç¦æ­¢ä½¿ç”¨é»˜è®¤å€¼
    'NO_EMPTY_FIELDS': True,  # ç¦æ­¢ç•™ç©ºï¼Œå¿…é¡»æ ‡è®°[NO DATA FOUND]
    'MUST_VERIFY_EACH_FIELD': True,  # æ¯ä¸ªå­—æ®µéƒ½è¦æœ‰æå–ä»£ç 
    'FORCE_DETAIL_PAGE': True,  # å¿…é¡»è¿›è¯¦æƒ…é¡µï¼Œä¸èƒ½åªçœ‹åˆ—è¡¨
}

def validate_strict_rules():
    """å¯åŠ¨æ—¶éªŒè¯ä¸¥æ ¼è§„åˆ™æ˜¯å¦ç”Ÿæ•ˆ"""
    print("ğŸ”´ STRICT RULES ACTIVATED:")
    for rule, value in STRICT_RULES.items():
        print(f"   âœ“ {rule} = {value}")
```

### è§„åˆ™2ï¼šå­—æ®µçº§åˆ«çš„å¼ºåˆ¶æ£€æŸ¥
```python
# æ¯ä¸ªäº§å“å¿…é¡»æ£€æŸ¥æ‰€æœ‰12ä¸ªå­—æ®µ
REQUIRED_FIELDS = [
    'COMPANY',
    'LOAN_TYPE',
    'REQUIRED_DOC',
    'FEATURES',
    'BENEFITS',
    'FEES_CHARGES',
    'TENURE',
    'RATE',
    'APPLICATION_FORM',
    'PRODUCT_DISCLOSURE',
    'TERMS_CONDITIONS',
    'BORROWER_PREFERENCE'
]

def enforce_field_check(product_data):
    """å¼ºåˆ¶æ£€æŸ¥æ‰€æœ‰å­—æ®µæ˜¯å¦éƒ½è¢«å¤„ç†"""
    for field in REQUIRED_FIELDS:
        if field not in product_data:
            raise ValueError(f"âŒ FATAL: Missing field {field}")
        
        # å¦‚æœå­—æ®µæ˜¯Noneï¼Œå¿…é¡»æ›¿æ¢ä¸º[NO DATA FOUND]
        if product_data[field] is None:
            product_data[field] = '[NO DATA FOUND]'
        
        # ä¸è®¸æ˜¯ç©ºå­—ç¬¦ä¸²
        if product_data[field] == '':
            product_data[field] = '[NO DATA FOUND]'
        
        # ä¸è®¸æ˜¯'N/A', 'NA', 'unknown'è¿™ç±»æ¨¡ç³Šå€¼
        if product_data[field].lower() in ['n/a', 'na', 'unknown', 'not available', 'tbd', 'å¾…å®š']:
            product_data[field] = '[NO DATA FOUND]'
    
    print(f"âœ… Field check passed for {product_data.get('LOAN_TYPE', 'unknown')}")
    return product_data
```

### è§„åˆ™3ï¼šå¼ºåˆ¶å®Œæ•´é’»æ¢æ—¥å¿—
```python
class ExtractionAudit:
    """å®¡è®¡æ¯ä¸€æ­¥æ˜¯å¦çœŸçš„å®Œæˆ"""
    
    def __init__(self, company_name):
        self.company = company_name
        self.audit_log = []
        self.product_count = 0
    
    def log_list_page_fetch(self, url, found_count):
        """è®°å½•åˆ—è¡¨é¡µè·å–"""
        self.audit_log.append({
            'step': 'FETCH_LIST_PAGE',
            'url': url,
            'product_count': found_count,
            'time': datetime.now().isoformat()
        })
        print(f"  ğŸ“‹ List page: {found_count} products found")
    
    def log_detail_page_extract(self, product_name, fields_extracted):
        """è®°å½•è¯¦æƒ…é¡µæå–"""
        self.audit_log.append({
            'step': 'EXTRACT_DETAIL_PAGE',
            'product': product_name,
            'fields': fields_extracted,
            'time': datetime.now().isoformat()
        })
        self.product_count += 1
        print(f"  âœ… Detail page: {len(fields_extracted)} fields extracted")
    
    def log_field_not_found(self, field_name):
        """æ˜ç¡®è®°å½•å­—æ®µæœªæ‰¾åˆ°"""
        self.audit_log.append({
            'step': 'FIELD_NOT_FOUND',
            'field': field_name,
            'action': 'Marked as [NO DATA FOUND]',
            'time': datetime.now().isoformat()
        })
    
    def save_audit(self):
        """ä¿å­˜å®¡è®¡æ—¥å¿—"""
        audit_file = f"audit_{self.company}.json"
        with open(audit_file, 'w', encoding='utf-8') as f:
            json.dump(self.audit_log, f, ensure_ascii=False, indent=2, default=str)
        print(f"  ğŸ” Audit log saved: {audit_file}")
```

### è§„åˆ™4ï¼šå¼ºåˆ¶é¡ºåº+é˜²é—å¿˜
```python
class CompanyProcessor:
    """ä¸¥æ ¼é¡ºåºå¤„ç†ï¼Œé˜²æ­¢é—æ¼"""
    
    def __init__(self, companies_df):
        self.companies = companies_df
        self.processed = []
        self.skipped = []
        self.checkpoint_file = 'checkpoint.json'
    
    def process_sequentially(self):
        """å¿…é¡»æŒ‰é¡ºåºå¤„ç†ï¼Œä¸èƒ½è·³è¿‡"""
        for idx, row in self.companies.iterrows():
            company_name = row['å…¬å¸åç§°']
            
            # ã€å¼ºåˆ¶ã€‘æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡
            if self._is_already_processed(company_name):
                print(f"â­ï¸  Skipping {company_name} (already processed)")
                continue
            
            # ã€å¼ºåˆ¶ã€‘æŒ‰é¡ºåºå¤„ç†ï¼Œå®Œå…¨å®Œæˆæ‰è¿›ä¸‹ä¸€ä¸ª
            print(f"\n{'='*80}")
            print(f"ğŸ”´ MUST COMPLETE: Company {idx+1}/67 - {company_name}")
            print(f"{'='*80}")
            
            # å¤„ç†é€»è¾‘...
            # products = self._extract_all_products(row)
            
            # ã€å¼ºåˆ¶ã€‘ç¡®è®¤å®Œæˆæ‰æ ‡è®°
            self._mark_as_processed(company_name)
            self._save_checkpoint()
    
    def _is_already_processed(self, company_name):
        return company_name in self.processed
    
    def _mark_as_processed(self, company_name):
        self.processed.append(company_name)
    
    def _save_checkpoint(self):
        """å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹ï¼Œé˜²æ­¢ä¸­é€”é—å¿˜"""
        with open(self.checkpoint_file, 'w', encoding='utf-8') as f:
            json.dump({
                'processed': self.processed,
                'skipped': self.skipped,
                'total': len(self.companies),
                'progress_percent': len(self.processed) / len(self.companies) * 100,
                'timestamp': datetime.now().isoformat()
            }, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ Checkpoint saved: {len(self.processed)}/{len(self.companies)}")
```

### è§„åˆ™5ï¼šå¤šé€‰æ‹©å™¨å°è¯• + è¯¦ç»†æ—¥å¿—
```python
def extract_with_fallback(soup, field_name, extraction_methods):
    """
    å°è¯•å¤šä¸ªæå–æ–¹æ³•ï¼Œè®°å½•æ¯æ¬¡å°è¯•
    
    Args:
        soup: BeautifulSoupå¯¹è±¡
        field_name: å­—æ®µåç§°
        extraction_methods: æå–æ–¹æ³•åˆ—è¡¨ [(æ–¹æ³•å, å‡½æ•°), ...]
    
    Returns:
        (æå–ç»“æœ, ä½¿ç”¨çš„æ–¹æ³•)
    """
    print(f"\n  ğŸ” Extracting {field_name}...")
    
    for method_name, extraction_func in extraction_methods:
        try:
            result = extraction_func(soup)
            if result and result != '[NO DATA FOUND]':
                print(f"     âœ… Found using method: {method_name}")
                return result, method_name
            else:
                print(f"     âš ï¸  Method {method_name}: no data")
        except Exception as e:
            print(f"     âŒ Method {method_name} failed: {str(e)}")
    
    # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†
    print(f"     ğŸ”´ ALL METHODS FAILED for {field_name}")
    return '[NO DATA FOUND]', 'NONE'

# ä½¿ç”¨ç¤ºä¾‹
def extract_rate_field(soup):
    methods = [
        ('keyword_search', lambda s: extract_by_keywords(s, ['interest rate', 'rate', 'åˆ©ç‡'])),
        ('table_extraction', lambda s: extract_from_table(s, 'rate')),
        ('spec_box', lambda s: extract_from_spec_section(s, 'rate')),
        ('json_ld_schema', lambda s: extract_from_json_ld(s, 'rate')),
    ]
    result, method_used = extract_with_fallback(soup, 'RATE', methods)
    return result
```

### è§„åˆ™6ï¼šæ•°æ®è´¨é‡éªŒè¯
```python
class DataQualityChecker:
    """éªŒè¯æ•°æ®è´¨é‡ï¼Œé˜²æ­¢åƒåœ¾æ•°æ®"""
    
    @staticmethod
    def validate_product(product_data):
        """æ£€æŸ¥äº§å“æ•°æ®æ˜¯å¦ç¬¦åˆè´¨é‡æ ‡å‡†"""
        issues = []
        
        # æ£€æŸ¥1ï¼šä¸èƒ½æ‰€æœ‰å­—æ®µéƒ½æ˜¯[NO DATA FOUND]
        no_data_count = sum(1 for v in product_data.values() 
                           if v == '[NO DATA FOUND]')
        if no_data_count > 8:  # è¶…è¿‡8ä¸ªå­—æ®µæ²¡æ•°æ®
            issues.append(f"âš ï¸  Too many [NO DATA FOUND] fields ({no_data_count}/12)")
        
        # æ£€æŸ¥2ï¼šCOMPANYå’ŒLOAN_TYPEå¿…é¡»æœ‰å€¼
        if product_data['COMPANY'] == '[NO DATA FOUND]':
            issues.append(f"âŒ FATAL: COMPANY field is empty")
            return False
        
        if product_data['LOAN_TYPE'] == '[NO DATA FOUND]':
            issues.append(f"âŒ FATAL: LOAN_TYPE field is empty")
            return False
        
        # æ£€æŸ¥3ï¼šæ£€æŸ¥æ˜¯å¦æ˜¯åˆæˆæ•°æ®ï¼ˆä¾‹å¦‚æ‰€æœ‰å­—æ®µéƒ½ä¸€æ ·ï¼‰
        values = [str(v).lower() for v in product_data.values() if v]
        if len(set(values)) < 3:
            issues.append(f"âŒ Suspicious: too many duplicate values")
            return False
        
        # æ£€æŸ¥4ï¼šé•¿åº¦åˆç†æ€§
        for field, value in product_data.items():
            if isinstance(value, str):
                if len(value) > 1000:
                    issues.append(f"âš ï¸  {field} too long ({len(value)} chars)")
        
        if issues:
            print("\n".join(issues))
            return len([i for i in issues if i.startswith('âŒ')]) == 0
        
        return True

    @staticmethod
    def generate_quality_report(all_products):
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        print(f"\n{'='*80}")
        print("ğŸ“Š DATA QUALITY REPORT")
        print(f"{'='*80}")
        
        total = len(all_products)
        complete = sum(1 for p in all_products if DataQualityChecker.validate_product(p))
        no_data_rate = sum(1 for p in all_products 
                          for v in p.values() if v == '[NO DATA FOUND]') / (total * 12) * 100
        
        print(f"Total products: {total}")
        print(f"Valid products: {complete} ({complete/total*100:.1f}%)")
        print(f"[NO DATA FOUND] rate: {no_data_rate:.1f}%")
        
        # æŒ‰å…¬å¸åˆ†ç±»ç»Ÿè®¡
        companies = {}
        for product in all_products:
            company = product['COMPANY']
            if company not in companies:
                companies[company] = {'count': 0, 'no_data_rate': 0}
            companies[company]['count'] += 1
        
        print(f"\nProducts per company (top 5):")
        for company, stats in sorted(companies.items(), 
                                    key=lambda x: x[1]['count'], 
                                    reverse=True)[:5]:
            print(f"  - {company}: {stats['count']} products")
```

---

## æœ€ç»ˆé›†æˆæ£€æŸ¥æ¸…å•

### âœ… å‰æœŸæ£€æŸ¥ï¼ˆè¿è¡Œå‰ï¼‰
- [ ] ä»£ç ä¸­æ˜ç¡®å®šä¹‰STRICT_RULES = {æ‰€æœ‰è§„åˆ™éƒ½æ˜¯True}
- [ ] å¼ºåˆ¶å­—æ®µæ£€æŸ¥å‡½æ•°å·²é›†æˆ
- [ ] å®¡è®¡æ—¥å¿—ç±»å·²å®ä¾‹åŒ–
- [ ] è¿›åº¦æ£€æŸ¥ç‚¹æ–‡ä»¶å·²é…ç½®

### âœ… è¿è¡Œä¸­ç›‘æ§
- [ ] æ¯å®¶å…¬å¸æ‰“å°"="*80åˆ†éš”ç¬¦
- [ ] æ¯ä¸ªäº§å“æ˜¾ç¤ºä»åˆ—è¡¨é¡µâ†’è¯¦æƒ…é¡µâ†’å­—æ®µæå–è¿‡ç¨‹
- [ ] æ¯ä¸ªå­—æ®µæå–å¤±è´¥éƒ½æœ‰log
- [ ] è¿›åº¦å®šæ—¶ä¿å­˜ï¼ˆæ¯å…¬å¸åï¼‰

### âœ… å®ŒæˆåéªŒè¯
- [ ] æ€»è¡¨è¡Œæ•° > 100ï¼ˆå¦‚æœ<100ï¼Œè¯´æ˜æŠ“å¾—å¤ªå°‘ï¼‰
- [ ] [NO DATA FOUND]æ¯”ç‡ < 15%ï¼ˆå¤ªå¤šè¯´æ˜æ–¹æ³•ä¸å¯¹ï¼‰
- [ ] æ¯å®¶å…¬å¸è‡³å°‘1-2æ¡äº§å“è®°å½•ï¼ˆå¦‚æœ=0ï¼Œæ£€æŸ¥ç½‘ç«™ç»“æ„ï¼‰
- [ ] éšæœºæŠ½å–5å®¶å…¬å¸ï¼Œæ‰‹åŠ¨æµè§ˆç½‘ç«™éªŒè¯æ•°æ®
- [ ] æ²¡æœ‰ä¸¤è¡Œå®Œå…¨ç›¸åŒçš„äº§å“è®°å½•

---

## å‘½ä»¤è¡Œè¿è¡Œæ—¶å¼ºåˆ¶å‚æ•°

```bash
# å¯ç”¨ä¸¥æ ¼æ¨¡å¼
python solution.py --strict-mode=true

# å¯ç”¨è¯¦ç»†æ—¥å¿—
python solution.py --verbose=true

# å¯ç”¨æ•°æ®éªŒè¯
python solution.py --validate=true

# å®Œæ•´å‘½ä»¤
python solution.py --strict-mode=true --verbose=true --validate=true --output-dir=./output
```

---

## æœ€åçš„è¯

è¿™äº›è§„åˆ™ä¸æ˜¯å»ºè®®ï¼Œè€Œæ˜¯**å¼ºåˆ¶æªæ–½**ã€‚Replitå€¾å‘äºï¼š
- ğŸš« ç•™ç©ºå­—æ®µè€Œä¸æ˜¯æ ‡è®°NO DATA FOUND
- ğŸš« åªçœ‹åˆ—è¡¨é¡µè€Œä¸è¿›è¯¦æƒ…é¡µ  
- ğŸš« ç½‘é¡µå¤æ‚äº†å°±ç”¨é»˜è®¤æ•°æ®
- ğŸš« ä¸­é€”æ”¾å¼ƒæŸä¸ªå­—æ®µ

ä½ çš„ä»£ç å¿…é¡»åœ¨æ¯ä¸€æ­¥éƒ½**æ˜¾å¼éªŒè¯**å’Œ**å®¡è®¡**è¿™äº›è¡Œä¸ºï¼Œç¡®ä¿Replitä¸èƒ½å·æ‡’ã€‚

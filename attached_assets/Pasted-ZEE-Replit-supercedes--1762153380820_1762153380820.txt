ZEE，我把你那份“最终合并版”完整翻成英文镜像，并追加一套“防幻想/防失忆/防偷懒”的强约束方案（可直接给 Replit 落地执行）。这版不会与前文冲突；如有重叠，以此版为准（supercedes）。

⸻

▶️ Unified Build Order (Final Merged) — Copy-Paste for Replit

0) Goal (one sentence)

Backend (FastAPI:8000) becomes the single parsing & validation engine (reusing the 15-bank parsers from Savings). Frontend (Flask:5000) only does “ingest files + display + drive next steps.”
All behavior is driven by a 7-state machine; every upload (success or failure) redirects to the detail page; all anomalies go to the Exception Center; no “ask-the-user” prompts for next actions.

⸻

1) Scope & Principles
	•	Engine 1 (Flask 5000): Upload entrypoints / UI / i18n / navigation / list & detail pages / next-step guidance.
	•	Engine 2 (FastAPI 8000): Raw original vault (raw_documents/raw_lines) / parsing / validation / Exception Center / accounting postings / reporting / audit / file index.
	•	Parsing lives in ONE place only: extract the 15 Malaysia bank statement parsers from Savings into a shared library under FastAPI; Flask never parses, it only uploads.
	•	Keep existing tables: raw_documents, raw_lines, file_index, audit_logs, exceptions, auto_posting_rules, report_snapshots, period_closing. Use ALTER as needed; do not re-create.

⸻

2) Single Source of Truth: 7-State Machine (drives buttons & routing)

uploaded | active | failed | duplicate | validated | posted | archived

All frontend buttons/redirects/prompts must be derived only from these states — no ad-hoc logic.

status	Buttons (ordered)	Human note
uploaded	Verify / View Original	“File uploaded, not yet verified. Click Verify to continue.”
active	Generate Report / Download Original	“File verified; ready for reporting / bank package.”
failed	View Exceptions / Reprocess / Download Original	“Original archived, but structural/row issues exist (see exceptions).”
duplicate	Set as Primary / View Other Files / Download Original	“Primary statement for this company+account+month already exists.”
validated	Generate Report / Download Original	“Verification passed; report not generated yet.”
posted	View Report / Download Original	“Period is closed. View only; cannot overwrite.”
archived	Download Original	“Historical file (view only).”


⸻

3) Unify Parsers (lift 15-bank logic from Savings into FastAPI)

3.1 Layout & Interfaces

accounting_app/
  parsers/
    __init__.py
    registry.py
    column_map.py
    maybank.py
    cimb.py
    public_bank.py
    rhb.py
    hlb.py
    ... (total 15)

Types & contracts

# registry.py
from decimal import Decimal
from typing import TypedDict, Optional, List

class ParsedRow(TypedDict):
    date: str           # 'YYYY-MM-DD'
    description: str
    debit: Decimal
    credit: Decimal
    balance: Decimal
    reference: str
    meta: dict
    page_no: int
    line_no: int

class ParseResult(TypedDict):
    success: bool
    rows: List[ParsedRow]
    parser_version: str
    warnings: List[str]
    bank_code: str

def parse_pdf(binary: bytes, *, bank_code: str) -> ParseResult: ...
def parse_csv(text: str, *, bank_code: str) -> ParseResult: ...
def detect_bank_code(filename: str, first_page_text: str | None) -> Optional[str]: ...
def get_supported_banks() -> List[str]: ...

3.2 Normalization rules
	•	Dates → YYYY-MM-DD.
	•	Amounts → Decimal (no float); only one of (debit, credit) > 0 per row; standardized sign.
	•	Line provenance → fill page_no & line_no for every row; used to populate raw_lines and raw_line_id.
	•	Column aliases → column_map.py maps bank-specific headers to the canonical 6 columns (Date/Description/Debit/Credit/Balance/Reference).

⸻

4) Import Endpoint Overhaul (FastAPI /api/v2/import/bank-statement)

4.1 Request & Flow
	•	New param: bank_code (optional), file accepts PDF or CSV.
	•	Unified flow:
	1.	Write to raw_documents first (original vault, validation_status='pending') → persist raw_document_id (store also in request.state).
	2.	If PDF: try text extraction; if no text → scanned → return 400 with friendly message (see 4.3). Otherwise detect_bank_code() and call parse_pdf().
	3.	If CSV: if bank_code present, use bank-specific mapping; otherwise use general CSV validator + column_map → call parse_csv().
	4.	Write all returned rows to raw_lines (include parser_version/page_no/line_no).
	5.	Two-layer validation:
	•	Layer 1 (structure): must have 6 required columns. If missing → 422 failed, create exception missing_required_columns, but original remains archived (return raw_document_id).
	•	Layer 2 (row reconciliation): if raw_lines count mismatch vs parsed, do not block; set status='active', create ingest_validation_failed in Exception Center.
	6.	On success: write bank_statements/bank_statement_lines (must include raw_line_id); populate file_index with company_id/account_number/period/status.
	7.	Duplicate detection: company_id + account_number + period → status='duplicate' and return existing_file_id.
	8.	Respond with unified payload (4.2), next_actions from state-machine mapping.

4.2 Unified Response (both success & failure)

# schemas/responses.py
from typing import List, Optional, Literal
from pydantic import BaseModel
Status = Literal["uploaded","active","failed","duplicate","validated","posted","archived"]

class UploadResponse(BaseModel):
    success: bool
    status: Status
    raw_document_id: Optional[int] = None
    file_id: Optional[int] = None
    company_id: Optional[int] = None
    statement_month: Optional[str] = None
    account_number: Optional[str] = None
    status_reason: Optional[str] = None
    next_actions: List[str] = []
    warnings: List[str] = []
    existing_file_id: Optional[int] = None

Requirement: on 400/422 failures you still return raw_document_id and a human status_reason.

4.3 Scanned-PDF friendly message (replace “Only CSV…”)
	•	HTTP 400 + status="failed".
	•	ZH: “这是扫描版/图片对账单，请从网银下载 CSV/Excel 再上传。”
	•	EN: “This is a scanned/image statement. Please download the CSV/Excel version from e-banking and re-upload.”

⸻

5) Frontend (Flask 5000)

5.1 One upload callback (use everywhere)

const detail = data?.detail || data || {};
const fileId = detail.file_id || detail.raw_document_id;
if (fileId) {
  window.location.href = `/files/detail/${fileId}?highlight=${fileId}`;
} else {
  alert(i18n("upload_failed_generic"));
}

Always redirect to detail; never stay on upload screen.

5.2 PDF client-conversion toggle (avoid conflicts)
	•	Default OFF: send PDF as-is to backend parser.
	•	Env flag FRONTEND_PDF_CLIENT_CONVERT=false. If set true, enable client-side PDF→CSV as a temporary fallback only.

5.3 Detail/List rendering = state machine only
	•	Detail: buttons & note strictly from the 7-state table; if the endpoint is not implemented, pop: “Backend API not implemented: /api/… please complete.”
	•	List:
	•	parse ?highlight={id} → add .highlighted-file-row;
	•	show “Next step” column from state:
	•	uploaded → Verify this file
	•	active → Generate report
	•	failed → See Exception Center
	•	duplicate → Choose primary
	•	Language does not change URLs: always /files/detail/{id}?highlight={id}. Copy changes via i18n.

5.4 Supported bank list widget
	•	New GET /api/parsers/supported (FastAPI returns registered banks & supported types).
	•	Show a bilingual table + bank_code dropdown (default “Auto-Detect”).

⸻

6) Must-enter Exception Center (do not push work back to user)
	•	missing_required_columns → 422 failed, next_action="fix_csv".
	•	ingest_validation_failed → 200 active, next_action="retry_import".
	•	duplicate_statement → 200 duplicate, next_action="choose_primary", include existing_file_id.
Payload fields (min): raw_document_id, company_id, status='open', exception_type, next_action, retryable(bool).

⸻

7) Config & Security
	•	RBAC: write actions (upload/verify/set_primary/etc.) require require_role(admin|accountant).
	•	Audit: log upload/verify/export/exception ops with ip/user_agent.
	•	i18n: all new strings in lang/en.json & lang/zh.json; no hardcoded text.
	•	Feature flags (.env):
	•	FRONTEND_PDF_CLIENT_CONVERT=false
	•	PARSER_ENABLED_BANKS="maybank,cimb,public_bank,rhb,hlb,..."
	•	TASK_SECRET_TOKEN / SECRET_KEY

⸻

8) Tests & Delivery (must run & must paste real outputs)

A Standard (Maybank or any supported bank) PDF/CSV → expect 200, success=true, status=active, next_actions includes generate_report.
B Missing columns CSV → expect 422, success=false, status=failed + Exception missing_required_columns, must return raw_document_id.
C Duplicate month → expect 200, success=true, status=duplicate + existing_file_id + next_actions=["set_as_primary","view_other_files"].

For each case, return:
	1.	Backend JSON (verbatim)
	2.	Frontend redirected URL (/files/detail/{id}?highlight={id})
	3.	List highlighted? (true/false)
	4.	Detail-page button texts (EN or ZH; must match the state table)

⸻

9) Definition of Done (DoD checklist)
	•	/api/parsers/supported lists all 15 banks
	•	/api/v2/import/bank-statement supports PDF/CSV + optional bank_code
	•	All responses conform to UploadResponse (failures also return raw_document_id)
	•	Scanned-PDF friendly message (400 + human text)
	•	Row mismatch → active + exception (do not block entire file)
	•	Missing columns → 422 failed + exception
	•	Duplicate → duplicate + existing_file_id
	•	Frontend unified upload callback → always redirect to detail
	•	List “Next step” + ?highlight highlighting
	•	Detail buttons strictly by 7-state mapping
	•	i18n coverage (no hardcoded messages)
	•	Audit/RBAC enforced

⸻

10) Rollout & Rollback
	•	Gradual: enable 5 banks first (maybank,cimb,public_bank,rhb,hlb) via PARSER_ENABLED_BANKS. Others fallback to general CSV mapping or return a guided message.
	•	If parser instability occurs, temporary switch FRONTEND_PDF_CLIENT_CONVERT=true as a fallback (not recommended long-term).

⸻

▶️ Anti-Hallucination / Anti-Amnesia / Anti-Laziness Guardrails (Add-On Pack)

Purpose: hard-wire the system to import 100% of transactions (no omission/addition/alteration), forbid “AI guessing,” and enforce two-pass verification (machine + human) before posting.

A) No-LLM Ingestion Policy (deterministic only)
	•	Add env: GEN_AI_DISABLED=true.
	•	In the ingestion path, ban any LLM/OCR heuristics that fabricate values.
	•	If PDF has no selectable text → classify as scanned → do not create any parsed rows; return the friendly 400 message (4.3).
	•	Only deterministic parsers in accounting_app/parsers/* may emit rows. No parser may synthesize rows except when a literal Opening Balance row is explicitly detected in text (then store its raw_line_id like others).

B) Chain-of-Custody & Completeness
	•	File checksum: store SHA256 of the original in raw_documents.file_hash.
	•	Page checksums: optional per-page SHA256 in raw_documents.metadata.
	•	Row counts:
	•	raw_documents.reported_line_count (from parser)
	•	raw_lines.count(document_id) (DB fact)
	•	Reconcile both; if mismatch → create ingest_validation_failed and set status='active' (do not block), store delta in exceptions.raw_data.

C) Schema Constraints (DB-level hard rules)

-- One-of debit/credit > 0; never both
ALTER TABLE bank_statement_lines
  ADD CONSTRAINT one_side_positive
  CHECK (
    (debit_amount > 0 AND credit_amount = 0)
    OR
    (credit_amount > 0 AND debit_amount = 0)
  );

-- raw_line_id required and valid
ALTER TABLE bank_statement_lines
  ALTER COLUMN raw_line_id SET NOT NULL;

ALTER TABLE bank_statement_lines
  ADD CONSTRAINT fk_raw_line
  FOREIGN KEY (raw_line_id) REFERENCES raw_lines(id);

-- Period uniqueness for primary file
ALTER TABLE file_index
  ADD CONSTRAINT unique_primary_per_period
  UNIQUE (company_id, account_number, period)
  DEFERRABLE INITIALLY DEFERRED;

D) Balance Walk (strict reconciliation)

Implement deterministic balance verification:

from decimal import Decimal

def verify_balance_walk(opening: Decimal, rows: list[ParsedRow], closing: Decimal, tolerance=Decimal("0.01")):
    bal = opening
    for i, r in enumerate(rows, start=1):
        bal = bal + r["credit"] - r["debit"]
        # If source provides per-row balance, compare it:
        if "balance" in r and r["balance"] is not None:
            if (bal - r["balance"]).copy_abs() > tolerance:
                return False, f"Row {i}: computed balance {bal} != statement balance {r['balance']}"
    if (bal - closing).copy_abs() > tolerance:
        return False, f"Closing mismatch: computed {bal} vs statement {closing}"
    return True, None

Rules:
	•	Require Opening Balance & Closing Balance when the bank format provides them; persist as bank_statements.opening_balance / closing_balance.
	•	If per-row balances exist, compare every step; if not, at least verify OB + Σcredit − Σdebit = CB.
	•	On any mismatch:
	•	set status='failed' only if structural (missing OB/CB when mandatory).
	•	otherwise: keep status='active' and log reconciliation_gap exception with exact offending row(s).
	•	Never auto-correct. Never round rows beyond bank’s scale.

E) Two-Pass Verification (machine + human)
	•	Add columns to bank_statement_lines:
	•	verified_by INT NULL, verified_at TIMESTAMP NULL, verify_note TEXT NULL.
	•	Add a Verify mode UI in detail page:
	•	shows each row with page_no:line_no provenance;
	•	keyboard support (J/K next/prev), checkbox “Mark Verified”;
	•	a sticky “Remaining n of N” counter;
	•	Postings/report buttons stay disabled until all rows are verified.
	•	Add an endpoint:
	•	POST /api/statements/{file_id}/verify-line → mark one row verified;
	•	POST /api/statements/{file_id}/verify-bulk → verify remaining after a diff preview.
	•	Require verified_count == total_count before enabling Generate Report or Post. Expose this in next_actions.

F) Idempotence & No-skip Guarantee
	•	Idempotent import key: (company_id, account_number, period, file_hash). If same hash arrives → return status duplicate immediately.
	•	For CSV: exact row count in CSV must equal inserted raw_lines & bank_statement_lines. If not, create exception and do not mark verified.
	•	For PDF: when text-based, ensure that each detected transaction maps 1:1 to a raw_line. No parser may “sample” or “skip” rows.
	•	Add nightly job (/tasks/reconcile) to compare:
	•	Σ(credits) − Σ(debits) delta vs OB/CB;
	•	raw_lines count == bank_statement_lines count;
	•	any drift creates data_drift_detected exception (P0).

G) Strict Validators (Pydantic + Service layer)
	•	Pydantic Model for a row: enforce non-null Date/Description and exact YYYY-MM-DD; forbid future dates; restrict to statement_month.
	•	Service-level validation:
	•	all rows must have customer_id mapping if your business requires; otherwise leave NULL but generate mapping_required exception and block posting until resolved;
	•	account number must match the one detected from the statement, not user input (prevent poisoning).

H) Operator Review Checklist (for Replit to follow on each file)
	•	1:1 original stored; SHA256 saved.
	•	Parser version recorded; raw_line_id present on every line.
	•	Required columns present; no None leaks on required fields.
	•	OB/CB verified; step-by-step balances aligned (or exceptions created).
	•	No generated/synthetic rows (except literal Opening Balance when present).
	•	All rows human-verified in UI; verified_count == total_count.
	•	Period duplicate rule enforced; primary set when needed.
	•	Exceptions (if any) have actionable next_action.
	•	Audit log written for upload/verify/actions.

I) Test Harness (what they must run & paste back)
	•	Golden files for at least 3 banks (1 PDF text-based, 1 CSV clean, 1 CSV missing columns).
	•	Property tests: ensure sum rule (OB + ΣC − ΣD = CB) holds or raises precise exception; ensure “one-of debit/credit” invariant; forbid both zero.
	•	Snapshot test: DB raw_lines count equals parsed rows count.

Return these artifacts:
	•	The 3 scenario JSONs (already in your format),
	•	A CSV export of exceptions table for those runs,
	•	A one-liner summary: rows={N}, verified={N}, exceptions={k}, status={state} for each file.

⸻

Short “English one-liner” to give Replit

“Lift the 15-bank parsers from Savings into FastAPI (accounting_app/parsers/*) and register them; make /api/v2/import/bank-statement the single PDF/CSV entry with the unified UploadResponse (failures return raw_document_id), drive UI strictly by the 7-state machine, always redirect to /files/detail/{id}?highlight={id}, and force exceptions into the Exception Center. Additionally, enforce the anti-hallucination pack: no LLM ingestion, per-row raw_line_id, strict balance walk, idempotent imports, and two-pass (machine+human) verification before posting. Deliver A/B/C real JSONs + detail URL + list highlight + detail buttons; pass the DoD checklist. If any DoD item fails, treat as incomplete.”

⸻

你要的“更准确的方法”已包含在上面的 D/E/F/G：
	•	逐笔连贯余额复核（Balance Walk）+ 期初/期末平衡公式双保；
	•	**强制逐笔手工确认（Two-Pass）**才能出报表/入账；
	•	DB 约束 + 任务巡检杜绝“偷懒漏行”；
	•	禁用生成式/猜测式抽取杜绝“幻想症”；
	•	环境开关保证可灰度/回滚。

把这份中英版直接给 Replit 执行即可。若他们仍在流程中“询问你要不要这样做”，就回一句：
“状态机是唯一真理；请按本指令完成并回传三场景的真实结果与DoD勾选表。未达标视为未完成。”